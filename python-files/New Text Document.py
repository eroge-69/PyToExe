import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import pyaudio
import wave
import threading
import numpy as np
import librosa
import sqlite3
import json
import requests
from datetime import datetime
import os
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
from scipy import signal
import pickle
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler

class DogSoundAnalyzer:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ØµØ¯Ø§ÛŒ Ø³Ú¯ v2.0")
        self.root.geometry("1200x800")
        self.root.configure(bg='#2c3e50')
        
        # Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø¶Ø¨Ø· ØµØ¯Ø§
        self.is_recording = False
        self.audio_data = []
        self.sample_rate = 44100
        self.chunk_size = 1024
        
        # Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…Ø­Ù„ÛŒ
        self.init_database()
        
        # Ù…Ø¯Ù„ AI Ù…Ø­Ù„ÛŒ
        self.load_ai_model()
        
        # Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ
        self.create_gui()
        
        # Ù„ÛŒØ³Øª Ù†Ú˜Ø§Ø¯Ù‡Ø§ÛŒ Ø³Ú¯
        self.dog_breeds = [
            "Ú˜Ø±Ù…Ù† Ø´Ù¾Ø±Ø¯", "Ù„Ø§Ø¨Ø±Ø§Ø¯ÙˆØ±", "Ú¯Ù„Ø¯Ù† Ø±ØªØ±ÛŒÙˆØ±", "Ø¨ÙˆÙ„Ø¯Ø§Ú¯", "Ù¾ÙˆØ¯Ù„",
            "Ø±ÙˆØªÙˆØ§ÛŒÙ„Ø±", "ÛŒÙˆØ±Ú©Ø´Ø§ÛŒØ±", "Ú†ÛŒÙ‡ÙˆØ¢Ù‡ÙˆØ¢", "Ù‡Ø§Ø³Ú©ÛŒ Ø³Ø§ÛŒØ¨Ø±ÛŒ", "Ø¯Ø§Ú©Ø³Ù‡ÙˆÙ†Ø¯",
            "Ø¨ÛŒÚ¯Ù„", "Ù¾Ø§Ù…Ø±Ø§Ù†ÛŒÙ†", "Ø´ÛŒÙ‡ ØªØ²Ùˆ", "Ø¨ÙˆØ±Ø¯Ø± Ú©Ù„ÛŒ", "Ø¨Ø§Ú©Ø³Ø±"
        ]
        
    def init_database(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…Ø­Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        self.conn = sqlite3.connect('dog_sounds.db')
        cursor = self.conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS sound_analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                breed TEXT,
                sound_type TEXT,
                frequency REAL,
                duration REAL,
                intensity REAL,
                meaning TEXT,
                timestamp DATETIME,
                confidence REAL
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS dog_profiles (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT,
                breed TEXT,
                age INTEGER,
                weight REAL,
                created_date DATETIME
            )
        ''')
        
        self.conn.commit()
        
    def load_ai_model(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ AI Ù…Ø­Ù„ÛŒ"""
        try:
            # Ø§Ú¯Ø± Ù…Ø¯Ù„ Ø§Ø² Ù‚Ø¨Ù„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†
            with open('dog_sound_model.pkl', 'rb') as f:
                self.model = pickle.load(f)
            with open('scaler.pkl', 'rb') as f:
                self.scaler = pickle.load(f)
        except:
            # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯
            self.create_ai_model()
    
    def create_ai_model(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯Ù„ AI Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØµØ¯Ø§"""
        # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
        sample_features = np.random.rand(1000, 10)  # 10 ÙˆÛŒÚ˜Ú¯ÛŒ ØµÙˆØªÛŒ
        sample_labels = np.random.choice(['ØºØ°Ø§_Ù…ÛŒØ®ÙˆØ§Ù‡Ù…', 'Ø¨Ø§Ø²ÛŒ_Ù…ÛŒØ®ÙˆØ§Ù‡Ù…', 'ØªØ±Ø³ÛŒØ¯Ù‡_Ø§Ù…', 
                                        'Ø®ÙˆØ´Ø­Ø§Ù„Ù…', 'Ø¯Ø±Ø¯_Ø¯Ø§Ø±Ù…', 'ØªÙ†Ù‡Ø§_Ø§Ù…'], 1000)
        
        self.scaler = StandardScaler()
        scaled_features = self.scaler.fit_transform(sample_features)
        
        self.model = RandomForestClassifier(n_estimators=100, random_state=42)
        self.model.fit(scaled_features, sample_labels)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„
        with open('dog_sound_model.pkl', 'wb') as f:
            pickle.dump(self.model, f)
        with open('scaler.pkl', 'wb') as f:
            pickle.dump(self.scaler, f)
    
    def create_gui(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ"""
        # Ø§Ø³ØªØ§ÛŒÙ„
        style = ttk.Style()
        style.theme_use('clam')
        
        # ÙØ±ÛŒÙ… Ø§ØµÙ„ÛŒ
        main_frame = tk.Frame(self.root, bg='#2c3e50')
        main_frame.pack(fill='both', expand=True, padx=10, pady=10)
        
        # Ø¹Ù†ÙˆØ§Ù†
        title_label = tk.Label(main_frame, text="ğŸ• ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ ØµØ¯Ø§ÛŒ Ø³Ú¯ ğŸ•", 
                              font=('Arial', 20, 'bold'), fg='#ecf0f1', bg='#2c3e50')
        title_label.pack(pady=10)
        
        # ÙØ±ÛŒÙ… Ø¨Ø§Ù„Ø§ÛŒÛŒ
        top_frame = tk.Frame(main_frame, bg='#34495e', relief='raised', bd=2)
        top_frame.pack(fill='x', pady=5)
        
        # Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ú˜Ø§Ø¯
        breed_frame = tk.Frame(top_frame, bg='#34495e')
        breed_frame.pack(side='left', padx=10, pady=10)
        
        tk.Label(breed_frame, text="Ù†Ú˜Ø§Ø¯ Ø³Ú¯:", font=('Arial', 12), 
                fg='#ecf0f1', bg='#34495e').pack()
        
        self.breed_var = tk.StringVar()
        breed_combo = ttk.Combobox(breed_frame, textvariable=self.breed_var, 
                                  values=self.dog_breeds, state='readonly', width=15)
        breed_combo.pack(pady=5)
        breed_combo.set("Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯")
        
        # Ø¯Ú©Ù…Ù‡ ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø± Ù†Ú˜Ø§Ø¯
        auto_breed_btn = tk.Button(breed_frame, text="ğŸ” ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø± Ù†Ú˜Ø§Ø¯", 
                                  command=self.auto_detect_breed, bg='#3498db', 
                                  fg='white', font=('Arial', 10))
        auto_breed_btn.pack(pady=5)
        
        # ÙØ±ÛŒÙ… Ø¶Ø¨Ø· Ùˆ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ
        audio_frame = tk.Frame(top_frame, bg='#34495e')
        audio_frame.pack(side='right', padx=10, pady=10)
        
        self.record_btn = tk.Button(audio_frame, text="ğŸ¤ Ø´Ø±ÙˆØ¹ Ø¶Ø¨Ø·", 
                                   command=self.toggle_recording, bg='#e74c3c', 
                                   fg='white', font=('Arial', 12, 'bold'))
        self.record_btn.pack(pady=5)
        
        upload_btn = tk.Button(audio_frame, text="ğŸ“ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ", 
                              command=self.upload_audio, bg='#27ae60', 
                              fg='white', font=('Arial', 12))
        upload_btn.pack(pady=5)
        
        # ÙØ±ÛŒÙ… ÙˆØ³Ø· - Ù†Ù…Ø§ÛŒØ´ Ø·ÛŒÙ ØµÙˆØªÛŒ
        spectrum_frame = tk.Frame(main_frame, bg='#34495e', relief='raised', bd=2)
        spectrum_frame.pack(fill='both', expand=True, pady=5)
        
        tk.Label(spectrum_frame, text="ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ø·ÛŒÙ ØµÙˆØªÛŒ", font=('Arial', 14, 'bold'), 
                fg='#ecf0f1', bg='#34495e').pack(pady=5)
        
        # Ù†Ù…ÙˆØ¯Ø§Ø± matplotlib
        self.fig, (self.ax1, self.ax2) = plt.subplots(2, 1, figsize=(10, 6))
        self.fig.patch.set_facecolor('#34495e')
        for ax in [self.ax1, self.ax2]:
            ax.set_facecolor('#2c3e50')
            ax.tick_params(colors='white')
            ax.spines['bottom'].set_color('white')
            ax.spines['top'].set_color('white')
            ax.spines['right'].set_color('white')
            ax.spines['left'].set_color('white')
        
        self.canvas = FigureCanvasTkAgg(self.fig, spectrum_frame)
        self.canvas.get_tk_widget().pack(fill='both', expand=True, padx=10, pady=10)
        
        # ÙØ±ÛŒÙ… Ù¾Ø§ÛŒÛŒÙ† - Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„
        result_frame = tk.Frame(main_frame, bg='#34495e', relief='raised', bd=2)
        result_frame.pack(fill='x', pady=5)
        
        tk.Label(result_frame, text="ğŸ” Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„", font=('Arial', 14, 'bold'), 
                fg='#ecf0f1', bg='#34495e').pack(pady=5)
        
        # Ù…ØªÙ† Ù†ØªØ§ÛŒØ¬
        self.result_text = tk.Text(result_frame, height=8, font=('Arial', 11), 
                                  bg='#2c3e50', fg='#ecf0f1', wrap='word')
        self.result_text.pack(fill='x', padx=10, pady=10)
        
        # Ù†ÙˆØ§Ø± ÙˆØ¶Ø¹ÛŒØª
        self.status_var = tk.StringVar()
        self.status_var.set("Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„...")
        status_bar = tk.Label(main_frame, textvariable=self.status_var, 
                             relief='sunken', anchor='w', bg='#95a5a6', fg='#2c3e50')
        status_bar.pack(fill='x', side='bottom')
        
    def toggle_recording(self):
        """Ø´Ø±ÙˆØ¹/ØªÙˆÙ‚Ù Ø¶Ø¨Ø· ØµØ¯Ø§"""
        if not self.is_recording:
            self.start_recording()
        else:
            self.stop_recording()
    
    def start_recording(self):
        """Ø´Ø±ÙˆØ¹ Ø¶Ø¨Ø· ØµØ¯Ø§"""
        self.is_recording = True
        self.record_btn.config(text="â¹ï¸ ØªÙˆÙ‚Ù Ø¶Ø¨Ø·", bg='#e74c3c')
        self.status_var.set("Ø¯Ø± Ø­Ø§Ù„ Ø¶Ø¨Ø·...")
        
        def record():
            p = pyaudio.PyAudio()
            stream = p.open(format=pyaudio.paInt16,
                           channels=1,
                           rate=self.sample_rate,
                           input=True,
                           frames_per_buffer=self.chunk_size)
            
            self.audio_data = []
            
            while self.is_recording:
                data = stream.read(self.chunk_size)
                self.audio_data.append(data)
            
            stream.stop_stream()
            stream.close()
            p.terminate()
            
            # ØªØ­Ù„ÛŒÙ„ ØµØ¯Ø§ÛŒ Ø¶Ø¨Ø· Ø´Ø¯Ù‡
            self.analyze_recorded_audio()
        
        threading.Thread(target=record, daemon=True).start()
    
    def stop_recording(self):
        """ØªÙˆÙ‚Ù Ø¶Ø¨Ø· ØµØ¯Ø§"""
        self.is_recording = False
        self.record_btn.config(text="ğŸ¤ Ø´Ø±ÙˆØ¹ Ø¶Ø¨Ø·", bg='#27ae60')
        self.status_var.set("Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„...")
    
    def analyze_recorded_audio(self):
        """ØªØ­Ù„ÛŒÙ„ ØµØ¯Ø§ÛŒ Ø¶Ø¨Ø· Ø´Ø¯Ù‡"""
        if not self.audio_data:
            return
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ numpy array
        audio_bytes = b''.join(self.audio_data)
        audio_np = np.frombuffer(audio_bytes, dtype=np.int16)
        
        # ØªØ­Ù„ÛŒÙ„ ØµØ¯Ø§
        self.analyze_audio_data(audio_np, self.sample_rate)
    
    def upload_audio(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ"""
        file_path = filedialog.askopenfilename(
            title="Ø§Ù†ØªØ®Ø§Ø¨ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ",
            filetypes=[("ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ", "*.wav *.mp3 *.flac *.ogg")]
        )
        
        if file_path:
            self.status_var.set("Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ...")
            try:
                # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ø§ librosa
                audio_data, sample_rate = librosa.load(file_path, sr=None)
                self.analyze_audio_data(audio_data, sample_rate)
            except Exception as e:
                messagebox.showerror("Ø®Ø·Ø§", f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„: {str(e)}")
                self.status_var.set("Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„")
    
    def analyze_audio_data(self, audio_data, sample_rate):
        """ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ"""
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ
            features = self.extract_audio_features(audio_data, sample_rate)
            
            # Ø±Ø³Ù… Ø·ÛŒÙ ØµÙˆØªÛŒ
            self.plot_audio_spectrum(audio_data, sample_rate)
            
            # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§ Ù…Ø¯Ù„ AI
            prediction = self.predict_dog_emotion(features)
            
            # ØªØ­Ù„ÛŒÙ„ Ù†Ú˜Ø§Ø¯ (Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… Ø§Ù†ØªØ®Ø§Ø¨)
            if self.breed_var.get() == "Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯":
                breed = self.detect_breed_from_audio(features)
                self.breed_var.set(breed)
            
            # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
            self.display_results(features, prediction)
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
            self.save_to_database(features, prediction)
            
            self.status_var.set("ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø´Ø¯")
            
        except Exception as e:
            messagebox.showerror("Ø®Ø·Ø§", f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„: {str(e)}")
            self.status_var.set("Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„")
    
    def extract_audio_features(self, audio_data, sample_rate):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ"""
        features = {}
        
        # ÙØ±Ú©Ø§Ù†Ø³ ØºØ§Ù„Ø¨
        frequencies = np.fft.rfftfreq(len(audio_data), 1/sample_rate)
        magnitude = np.abs(np.fft.rfft(audio_data))
        features['dominant_freq'] = frequencies[np.argmax(magnitude)]
        
        # Ù…Ø¯Øª Ø²Ù…Ø§Ù†
        features['duration'] = len(audio_data) / sample_rate
        
        # Ø´Ø¯Øª ØµØ¯Ø§
        features['intensity'] = np.mean(np.abs(audio_data))
        
        # MFCC ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13)
        features['mfcc_mean'] = np.mean(mfccs, axis=1)
        
        # Zero Crossing Rate
        features['zcr'] = np.mean(librosa.feature.zero_crossing_rate(audio_data))
        
        # Spectral Centroid
        features['spectral_centroid'] = np.mean(librosa.feature.spectral_centroid(y=audio_data, sr=sample_rate))
        
        # Chroma Features
        features['chroma'] = np.mean(librosa.feature.chroma_stft(y=audio_data, sr=sample_rate))
        
        return features
    
    def plot_audio_spectrum(self, audio_data, sample_rate):
        """Ø±Ø³Ù… Ø·ÛŒÙ ØµÙˆØªÛŒ"""
        self.ax1.clear()
        self.ax2.clear()
        
        # Ù…ÙˆØ¬ ØµÙˆØªÛŒ
        time = np.linspace(0, len(audio_data)/sample_rate, len(audio_data))
        self.ax1.plot(time, audio_data, color='#3498db')
        self.ax1.set_title('Ù…ÙˆØ¬ ØµÙˆØªÛŒ', color='white', fontsize=12)
        self.ax1.set_xlabel('Ø²Ù…Ø§Ù† (Ø«Ø§Ù†ÛŒÙ‡)', color='white')
        self.ax1.set_ylabel('Ø¯Ø§Ù…Ù†Ù‡', color='white')
        
        # Ø·ÛŒÙ ÙØ±Ú©Ø§Ù†Ø³ÛŒ
        frequencies = np.fft.rfftfreq(len(audio_data), 1/sample_rate)
        magnitude = np.abs(np.fft.rfft(audio_data))
        self.ax2.plot(frequencies, magnitude, color='#e74c3c')
        self.ax2.set_title('Ø·ÛŒÙ ÙØ±Ú©Ø§Ù†Ø³ÛŒ', color='white', fontsize=12)
        self.ax2.set_xlabel('ÙØ±Ú©Ø§Ù†Ø³ (Hz)', color='white')
        self.ax2.set_ylabel('Ù‚Ø¯Ø±Øª', color='white')
        self.ax2.set_xlim(0, 2000)  # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¨Ù‡ ÙØ±Ú©Ø§Ù†Ø³â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…
        
        self.canvas.draw()
    
    def predict_dog_emotion(self, features):
        """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø­Ø³Ø§Ø³ Ø³Ú¯"""
        # ØªØ¨Ø¯ÛŒÙ„ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ù‡ ÙØ±Ù…Øª Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„
        feature_vector = [
            features['dominant_freq'],
            features['duration'],
            features['intensity'],
            features['zcr'],
            features['spectral_centroid'],
            features['chroma'],
            np.mean(features['mfcc_mean'][:4])  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² 4 MFCC Ø§ÙˆÙ„
        ]
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØµØ§Ø¯ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªÚ©Ù…ÛŒÙ„ 10 ÙˆÛŒÚ˜Ú¯ÛŒ
        while len(feature_vector) < 10:
            feature_vector.append(np.random.rand())
        
        feature_vector = np.array(feature_vector).reshape(1, -1)
        scaled_features = self.scaler.transform(feature_vector)
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        prediction = self.model.predict(scaled_features)[0]
        confidence = np.max(self.model.predict_proba(scaled_features))
        
        return {
            'emotion': prediction,
            'confidence': confidence
        }
    
    def detect_breed_from_audio(self, features):
        """ØªØ´Ø®ÛŒØµ Ù†Ú˜Ø§Ø¯ Ø§Ø² Ø±ÙˆÛŒ ØµØ¯Ø§"""
        # Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§Ø³Ø§Ø³ ÙØ±Ú©Ø§Ù†Ø³ Ùˆ Ø´Ø¯Øª
        freq = features['dominant_freq']
        intensity = features['intensity']
        
        if freq > 800 and intensity > 0.1:
            return "Ú†ÛŒÙ‡ÙˆØ¢Ù‡ÙˆØ¢"  # Ø³Ú¯â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú© ØµØ¯Ø§ÛŒ Ø¨Ù„Ù†Ø¯ØªØ±ÛŒ Ø¯Ø§Ø±Ù†Ø¯
        elif freq > 600:
            return "ÛŒÙˆØ±Ú©Ø´Ø§ÛŒØ±"
        elif freq > 400:
            return "Ø¨ÛŒÚ¯Ù„"
        elif freq > 250:
            return "Ù„Ø§Ø¨Ø±Ø§Ø¯ÙˆØ±"
        else:
            return "Ú˜Ø±Ù…Ù† Ø´Ù¾Ø±Ø¯"  # Ø³Ú¯â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ ØµØ¯Ø§ÛŒ Ø¨Ù…â€ŒØªØ±ÛŒ Ø¯Ø§Ø±Ù†Ø¯
    
    def auto_detect_breed(self):
        """ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø± Ù†Ú˜Ø§Ø¯"""
        if hasattr(self, 'last_features'):
            breed = self.detect_breed_from_audio(self.last_features)
            self.breed_var.set(breed)
            messagebox.showinfo("ØªØ´Ø®ÛŒØµ Ù†Ú˜Ø§Ø¯", f"Ù†Ú˜Ø§Ø¯ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡: {breed}")
        else:
            messagebox.showwarning("Ù‡Ø´Ø¯Ø§Ø±", "Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯")
    
    def display_results(self, features, prediction):
        """Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„"""
        self.last_features = features  # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù†Ú˜Ø§Ø¯
        
        result_text = f"""
ğŸ” Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ ØµØ¯Ø§ÛŒ Ø³Ú¯:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ• Ù†Ú˜Ø§Ø¯: {self.breed_var.get()}
ğŸ˜Š Ø­Ø§Ù„Øª Ø§Ø­Ø³Ø§Ø³ÛŒ: {self.get_emotion_persian(prediction['emotion'])}
ğŸ“Š Ø¯Ø±Ø¬Ù‡ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {prediction['confidence']:.1%}

ğŸ“ˆ Ù…Ø´Ø®ØµØ§Øª ØµÙˆØªÛŒ:
â–«ï¸ ÙØ±Ú©Ø§Ù†Ø³ ØºØ§Ù„Ø¨: {features['dominant_freq']:.1f} Hz
â–«ï¸ Ù…Ø¯Øª Ø²Ù…Ø§Ù†: {features['duration']:.2f} Ø«Ø§Ù†ÛŒÙ‡  
â–«ï¸ Ø´Ø¯Øª ØµØ¯Ø§: {features['intensity']:.4f}
â–«ï¸ Ù†Ø±Ø® Ø¹Ø¨ÙˆØ± Ø§Ø² ØµÙØ±: {features['zcr']:.4f}

ğŸ’¡ ØªÙØ³ÛŒØ±:
{self.get_interpretation(prediction['emotion'], features)}

â° Ø²Ù…Ø§Ù† ØªØ­Ù„ÛŒÙ„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        """
        
        self.result_text.delete(1.0, tk.END)
        self.result_text.insert(1.0, result_text)
    
    def get_emotion_persian(self, emotion):
        """ØªØ¨Ø¯ÛŒÙ„ Ù†Ø§Ù… Ø§Ø­Ø³Ø§Ø³ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ"""
        translations = {
            'ØºØ°Ø§_Ù…ÛŒØ®ÙˆØ§Ù‡Ù…': 'Ú¯Ø±Ø³Ù†Ù‡ Ø§Ø³Øª / ØºØ°Ø§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡Ø¯',
            'Ø¨Ø§Ø²ÛŒ_Ù…ÛŒØ®ÙˆØ§Ù‡Ù…': 'Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡Ø¯ Ø¨Ø§Ø²ÛŒ Ú©Ù†Ø¯',
            'ØªØ±Ø³ÛŒØ¯Ù‡_Ø§Ù…': 'ØªØ±Ø³ÛŒØ¯Ù‡ Ø§Ø³Øª',
            'Ø®ÙˆØ´Ø­Ø§Ù„Ù…': 'Ø®ÙˆØ´Ø­Ø§Ù„ Ø§Ø³Øª',
            'Ø¯Ø±Ø¯_Ø¯Ø§Ø±Ù…': 'Ø¯Ø±Ø¯ Ø¯Ø§Ø±Ø¯ / Ù†Ø§Ø±Ø§Ø­Øª Ø§Ø³Øª',
            'ØªÙ†Ù‡Ø§_Ø§Ù…': 'Ø§Ø­Ø³Ø§Ø³ ØªÙ†Ù‡Ø§ÛŒÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯'
        }
        return translations.get(emotion, emotion)
    
    def get_interpretation(self, emotion, features):
        """ØªÙØ³ÛŒØ± Ù†ØªØ§ÛŒØ¬"""
        interpretations = {
            'ØºØ°Ø§_Ù…ÛŒØ®ÙˆØ§Ù‡Ù…': 'Ø³Ú¯ Ø´Ù…Ø§ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ú¯Ø±Ø³Ù†Ù‡ Ø§Ø³Øª Ùˆ Ø¨Ù‡ ØºØ°Ø§ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ø¯.',
            'Ø¨Ø§Ø²ÛŒ_Ù…ÛŒØ®ÙˆØ§Ù‡Ù…': 'Ø³Ú¯ Ø´Ù…Ø§ Ø§Ù†Ø±Ú˜ÛŒ Ø¯Ø§Ø±Ø¯ Ùˆ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡Ø¯ Ø¨Ø§Ø²ÛŒ Ú©Ù†Ø¯.',
            'ØªØ±Ø³ÛŒØ¯Ù‡_Ø§Ù…': 'Ø³Ú¯ Ø´Ù…Ø§ ØªØ±Ø³ÛŒØ¯Ù‡ Ø§Ø³Øª. Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ Ú†Ù‡ Ú†ÛŒØ²ÛŒ Ø§Ùˆ Ø±Ø§ ØªØ±Ø³Ø§Ù†Ø¯Ù‡.',
            'Ø®ÙˆØ´Ø­Ø§Ù„Ù…': 'Ø³Ú¯ Ø´Ù…Ø§ Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ¨ÛŒ Ø§Ø³Øª Ùˆ Ø§Ø­Ø³Ø§Ø³ Ø®ÙˆØ´ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.',
            'Ø¯Ø±Ø¯_Ø¯Ø§Ø±Ù…': 'Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø³Ú¯ Ø´Ù…Ø§ Ø¯Ø±Ø¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯. Ø¯Ø± ØµÙˆØ±Øª Ø§Ø¯Ø§Ù…Ù‡ØŒ Ø¨Ù‡ Ø¯Ø§Ù…Ù¾Ø²Ø´Ú© Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ù†ÛŒØ¯.',
            'ØªÙ†Ù‡Ø§_Ø§Ù…': 'Ø³Ú¯ Ø´Ù…Ø§ Ø§Ø­Ø³Ø§Ø³ ØªÙ†Ù‡Ø§ÛŒÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ø¨Ù‡ ØªÙˆØ¬Ù‡ Ø¨ÛŒØ´ØªØ± Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ø¯.'
        }
        
        base_interpretation = interpretations.get(emotion, 'Ù†ØªÛŒØ¬Ù‡ Ù…Ø´Ø®Øµ Ù†ÛŒØ³Øª.')
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙˆØ¶ÛŒØ­Ø§Øª Ø¨ÛŒØ´ØªØ± Ø¨Ø±Ø§Ø³Ø§Ø³ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
        if features['dominant_freq'] > 1000:
            base_interpretation += "\nâ–«ï¸ ÙØ±Ú©Ø§Ù†Ø³ Ø¨Ø§Ù„Ø§ÛŒ ØµØ¯Ø§ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù‡ÛŒØ¬Ø§Ù† ÛŒØ§ Ø§Ø³ØªØ±Ø³ Ø§Ø³Øª."
        
        if features['duration'] > 3:
            base_interpretation += "\nâ–«ï¸ Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø¨ÙˆØ¯Ù† ØµØ¯Ø§ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø§ØµØ±Ø§Ø± Ø³Ú¯ Ø§Ø³Øª."
            
        return base_interpretation
    
    def save_to_database(self, features, prediction):
        """Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³"""
        cursor = self.conn.cursor()
        cursor.execute('''
            INSERT INTO sound_analysis 
            (breed, sound_type, frequency, duration, intensity, meaning, timestamp, confidence)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            self.breed_var.get(),
            prediction['emotion'],
            features['dominant_freq'],
            features['duration'],
            features['intensity'],
            self.get_emotion_persian(prediction['emotion']),
            datetime.now(),
            prediction['confidence']
        ))
        self.conn.commit()
    
    def run(self):
        """Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡"""
        self.root.mainloop()
        self.conn.close()

# Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡
if __name__ == "__main__":
    try:
        app = DogSoundAnalyzer()
        app.run()
    except Exception as e:
        print(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡: {e}")
        input("Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ Enter Ø±Ø§ ÙØ´Ø§Ø± Ø¯Ù‡ÛŒØ¯...")
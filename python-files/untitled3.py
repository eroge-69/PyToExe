# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nqKJketyKJs676CvK-8SfA0f7n2RLnHx
"""

#!/usr/bin/env python3
"""
sales_analysis_gui.py

Single-file desktop GUI for quick diagnostics of sales declines.
Paste this into Notepad and save as sales_analysis_gui.py, then run:
    python sales_analysis_gui.py

Requires (recommended): pandas, numpy, matplotlib
Optional (for better stats): scipy

Minimal UX:
 - Open CSV
 - Choose recent period months and top-N products
 - Run analysis
 - View charts, tables, text summary in the app
 - Export an HTML report
"""
import os
import sys
import math
import io
import base64
from datetime import datetime
from textwrap import dedent
try:
    import tkinter as tk
    from tkinter import ttk, filedialog, messagebox
except Exception:
    print("Tkinter is required but not available in this Python build.")
    sys.exit(1)

# Try imports of analysis libs, give friendly error if missing
_missing = []
try:
    import pandas as pd
except Exception:
    pd = None
    _missing.append("pandas")
try:
    import numpy as np
except Exception:
    np = None
    _missing.append("numpy")
try:
    import matplotlib
    matplotlib.use("Agg")  # default until embedding
    import matplotlib.pyplot as plt
    from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
except Exception:
    plt = None
    FigureCanvasTkAgg = None
    _missing.append("matplotlib")
try:
    from scipy import stats
    _HAS_SCIPY = True
except Exception:
    stats = None
    _HAS_SCIPY = False

if _missing:
    # Provide a useful message in a GUI dialog when app starts
    pass  # handled later in UI

# ---------------- Utility helpers ----------------
def guess_col(cols, candidates):
    cols_low = {c.lower(): c for c in cols}
    for cand in candidates:
        if cand.lower() in cols_low:
            return cols_low[cand.lower()]
    for cand in candidates:
        for c in cols:
            if cand.lower() in c.lower():
                return c
    return None

def parse_date_column(df):
    for c in df.columns:
        if pd.api.types.is_datetime64_any_dtype(df[c]):
            return c
    for c in df.columns:
        if "date" in c.lower():
            try:
                df[c] = pd.to_datetime(df[c], errors='coerce')
                if df[c].notna().sum() > 0:
                    return c
            except Exception:
                continue
    first = df.columns[0]
    try:
        df[first] = pd.to_datetime(df[first], errors='coerce')
        if df[first].notna().sum() > 0:
            return first
    except Exception:
        pass
    return None

def welsch_ttest(a, b):
    n1, n2 = len(a), len(b)
    m1, m2 = float(np.nanmean(a)), float(np.nanmean(b))
    s1, s2 = float(np.nanvar(a, ddof=1)), float(np.nanvar(b, ddof=1))
    denom = math.sqrt(s1/n1 + s2/n2) if n1>0 and n2>0 else float('inf')
    t = (m1 - m2) / denom if denom>0 else float('nan')
    num = (s1/n1 + s2/n2)**2
    den = 0
    if n1>1:
        den += (s1/n1)**2 / (n1-1)
    if n2>1:
        den += (s2/n2)**2 / (n2-1)
    df_est = num / den if den>0 else float('nan')
    return t, df_est

def save_fig_to_base64(fig):
    buf = io.BytesIO()
    fig.savefig(buf, bbox_inches="tight", dpi=120)
    plt.close(fig)
    buf.seek(0)
    b64 = base64.b64encode(buf.read()).decode("ascii")
    return "data:image/png;base64," + b64

# ---------------- Core analysis (adapted & simplified) ----------------
def analyze_df(df, recent_period_months=3, top_n_products=10):
    # returns a dict with results, assets (base64 images), and diagnostics
    if pd is None:
        raise RuntimeError("pandas is required for analysis.")
    if np is None:
        raise RuntimeError("numpy is required for analysis.")

    df = df.copy()
    date_col = parse_date_column(df)
    if date_col is None:
        raise ValueError("Could not find/parse a date column in the CSV.")
    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
    df = df[df[date_col].notna()].copy()

    cols = df.columns.tolist()
    sales_col = guess_col(cols, ["sales", "revenue", "amount", "total"])
    units_col = guess_col(cols, ["units", "quantity", "qty", "count", "orders"])
    price_col = guess_col(cols, ["price", "unit_price", "avg_price"])
    product_col = guess_col(cols, ["product", "sku", "item", "product_id"])
    region_col = guess_col(cols, ["region", "state", "country", "market"])
    channel_col = guess_col(cols, ["channel", "sales_channel", "platform"])
    promo_col = guess_col(cols, ["promo", "promotion", "is_promo", "discount"])
    returns_col = guess_col(cols, ["return", "returns", "refund"])

    if sales_col is None and units_col is not None and price_col is not None:
        df["_sales_calc"] = pd.to_numeric(df[units_col], errors='coerce') * pd.to_numeric(df[price_col], errors='coerce')
        sales_col = "_sales_calc"

    if sales_col is None:
        raise ValueError("No sales/revenue column and could not compute sales from units*price.")

    df[sales_col] = pd.to_numeric(df[sales_col], errors='coerce').fillna(0)
    if units_col:
        try:
            df[units_col] = pd.to_numeric(df[units_col], errors='coerce').fillna(0)
        except Exception:
            units_col = None
    if price_col:
        try:
            df[price_col] = pd.to_numeric(df[price_col], errors='coerce')
        except Exception:
            price_col = None

    df['date'] = df[date_col].dt.date
    df['month'] = df[date_col].dt.to_period('M').dt.to_timestamp()
    df['week'] = df[date_col].dt.to_period('W').dt.start_time

    daily = df.groupby('date').agg(sales=(sales_col, 'sum'))
    daily['date'] = pd.to_datetime(daily.index)
    daily = daily.sort_values('date')

    monthly = df.groupby('month').agg(sales=(sales_col, 'sum'))
    monthly = monthly.sort_index()

    def pct(a, b):
        try:
            return (a - b) / b * 100.0 if b != 0 else float('nan')
        except Exception:
            return float('nan')

    if len(monthly) < 2:
        raise ValueError("Not enough monthly data for meaningful analysis.")

    recent_end = monthly.index.max()
    recent_start = (recent_end - pd.DateOffset(months=recent_period_months-1)).replace(day=1)
    recent_mask = (monthly.index >= recent_start) & (monthly.index <= recent_end)
    recent_total = float(monthly.loc[recent_mask, 'sales'].sum())
    prev_start = (recent_start - pd.DateOffset(months=recent_period_months)).replace(day=1)
    prev_mask = (monthly.index >= prev_start) & (monthly.index < recent_start)
    prev_total = float(monthly.loc[prev_mask, 'sales'].sum()) if prev_mask.any() else float('nan')
    pct_change_recent_vs_prev = pct(recent_total, prev_total) if not math.isnan(prev_total) else float('nan')

    monthly['ma3'] = monthly['sales'].rolling(3, min_periods=1).mean()
    monthly['pct_change'] = monthly['sales'].pct_change() * 100
    largest_drop = monthly['pct_change'].idxmin()
    largest_drop_val = float(monthly['pct_change'].min())

    product_table = None
    product_insights = ""
    if product_col:
        prod = df.groupby(product_col).agg(sales=(sales_col, 'sum'))
        prod = prod.sort_values('sales', ascending=False)
        total_sales = float(prod['sales'].sum()) if not prod.empty else 0.0
        prod['share_pct'] = prod['sales'] / total_sales * 100 if total_sales > 0 else 0.0
        top_now = prod.head(top_n_products)
        recent_mask_rows = (df[date_col] >= recent_start) & (df[date_col] <= recent_end + pd.offsets.MonthEnd(0))
        prev_mask_rows = (df[date_col] >= prev_start) & (df[date_col] < recent_start)
        recent_by_prod = df[recent_mask_rows].groupby(product_col)[sales_col].sum()
        prev_by_prod = df[prev_mask_rows].groupby(product_col)[sales_col].sum()
        prod_change = pd.DataFrame({'recent_sales': recent_by_prod, 'prev_sales': prev_by_prod}).fillna(0)
        prod_change['diff'] = prod_change['recent_sales'] - prod_change['prev_sales']
        prod_change['pct_diff'] = prod_change.apply(lambda r: pct(r['recent_sales'], r['prev_sales']), axis=1)
        prod_change = prod_change.sort_values('diff')
        top_losers = prod_change.loc[prod.index].dropna().sort_values('pct_diff').head(10)
        product_table = {
            'top_products': top_now.reset_index().to_dict(orient='records'),
            'top_losers': top_losers.reset_index().to_dict(orient='records'),
            'product_col': product_col
        }
        product_insights = f"Top {top_n_products} products account for {top_now['share_pct'].sum():.1f}% of total sales." if not top_now.empty else ""

    region_table = None
    channel_table = None
    if region_col:
        reg = df.groupby(region_col)[sales_col].sum().sort_values(ascending=False)
        region_table = reg.reset_index().to_dict(orient='records')
    if channel_col:
        ch = df.groupby(channel_col)[sales_col].sum().sort_values(ascending=False)
        channel_table = ch.reset_index().to_dict(orient='records')

    promo_stats = {}
    promo_insights = ""
    if promo_col and promo_col in df.columns:
        promo_series = df[promo_col].astype(str).str.lower().isin(['1','true','yes','y','t'])
        promo_sales = df.loc[promo_series, sales_col]
        nonpromo_sales = df.loc[~promo_series, sales_col]
        promo_stats['promo_rows'] = int(promo_series.sum())
        promo_stats['promo_sales_total'] = float(promo_sales.sum())
        promo_stats['nonpromo_sales_total'] = float(nonpromo_sales.sum())
        promo_stats['promo_avg_per_row'] = float(promo_sales.mean()) if len(promo_sales)>0 else float('nan')
        promo_stats['nonpromo_avg_per_row'] = float(nonpromo_sales.mean()) if len(nonpromo_sales)>0 else float('nan')
        if _HAS_SCIPY and len(promo_sales.dropna())>1 and len(nonpromo_sales.dropna())>1:
            t_stat, p_val = stats.ttest_ind(promo_sales.dropna(), nonpromo_sales.dropna(), equal_var=False)
            promo_stats['t_stat'] = float(t_stat)
            promo_stats['p_value'] = float(p_val)
        else:
            t, df_est = welsch_ttest(promo_sales.dropna().values if len(promo_sales)>0 else np.array([]),
                                     nonpromo_sales.dropna().values if len(nonpromo_sales)>0 else np.array([]))
            promo_stats['t_stat'] = float(t) if not math.isnan(t) else None
            promo_stats['df_est'] = float(df_est) if not math.isnan(df_est) else None
        promo_insights = dedent(f"""\
            Promo rows: {promo_stats.get('promo_rows',0)}, promo sales total: {promo_stats.get('promo_sales_total',0):.2f}.
            Avg per promo-row: {promo_stats.get('promo_avg_per_row', float('nan')):.2f} vs non-promo {promo_stats.get('nonpromo_avg_per_row', float('nan')):.2f}.
        """)

    price_corr = None
    price_insights = ""
    if price_col:
        try:
            corr_price_sales = float(df[[price_col, sales_col]].dropna().corr().iloc[0,1])
            corr_price_units = None
            if units_col:
                corr_price_units = float(df[[price_col, units_col]].dropna().corr().iloc[0,1])
            price_corr = {'price_sales_corr': corr_price_sales, 'price_units_corr': corr_price_units}
            price_insights = "Price correlations computed."
        except Exception:
            price_insights = "Price correlation analysis failed."

    daily['rolling30'] = daily['sales'].rolling(30, min_periods=7).mean()
    daily['rolling30_std'] = daily['sales'].rolling(30, min_periods=7).std()
    daily['rolling_z'] = (daily['sales'] - daily['rolling30']) / daily['rolling30_std']
    anomalies = daily[daily['rolling_z'] < -2.5].reset_index()

    # charts (matplotlib)
    assets = {}
    # Use Agg backend for file saving, but for embedding in Tk we need TkAgg; switch later if embedding
    if plt is not None:
        # daily plot
        fig1, ax1 = plt.subplots(figsize=(8,3))
        ax1.plot(daily['date'], daily['sales'], label='daily sales')
        ax1.plot(daily['date'], daily['rolling30'], label='30d MA', linewidth=1)
        ax1.set_title("Daily sales with 30d moving average")
        ax1.set_xlabel("")
        ax1.set_ylabel("Sales")
        ax1.legend(frameon=False)
        assets['daily_ts'] = save_fig_to_base64(fig1)

        # monthly
        fig2, ax2 = plt.subplots(figsize=(8,3))
        ax2.bar(monthly.index.to_pydatetime(), monthly['sales'], label='monthly sales')
        ax2.plot(monthly.index.to_pydatetime(), monthly['ma3'], label='3mo MA', linewidth=2)
        ax2.set_title("Monthly sales and 3-month MA")
        ax2.set_xlabel("")
        ax2.set_ylabel("Sales")
        ax2.legend(frameon=False)
        assets['monthly_ts'] = save_fig_to_base64(fig2)

        if product_table and product_table.get('top_products'):
            prod_df = pd.DataFrame(product_table['top_products']).head(top_n_products)
            fig3, ax3 = plt.subplots(figsize=(6,4))
            ax3.barh(prod_df[product_table['product_col']].astype(str), prod_df['sales'])
            ax3.invert_yaxis()
            ax3.set_title(f"Top {top_n_products} products by sales")
            assets['top_products'] = save_fig_to_base64(fig3)

        if region_table:
            reg_df = pd.DataFrame(region_table).head(10)
            fig4, ax4 = plt.subplots(figsize=(6,4))
            ax4.barh(reg_df[0].astype(str), reg_df[1])
            ax4.invert_yaxis()
            ax4.set_title("Top regions by sales")
            assets['region'] = save_fig_to_base64(fig4)

    # Compose reasons
    reasons = []
    if units_col and 'units' in monthly.columns:
        recent_units = monthly.loc[recent_mask, 'units'].sum() if 'units' in monthly.columns else None
    # check price elasticity
    if price_corr and price_corr.get('price_units_corr') is not None and price_corr['price_units_corr'] < -0.2:
        reasons.append("Negative correlation between price and units suggests price increases may have reduced volume.")
    if promo_insights:
        reasons.append("Promotion cadence/discounting differences detected; check promo schedule.")
    if largest_drop_val and not math.isnan(largest_drop_val) and largest_drop_val < -20:
        reasons.append(f"Largest month-over-month drop: {largest_drop_val:.1f}% in {largest_drop.strftime('%Y-%m')}. Investigate that month.")
    if product_table:
        # simple top-product share decrease check
        top_idx = [r[product_table['product_col']] for r in product_table['top_products'][:top_n_products]]
        recent_top = df[recent_mask].groupby(product_col)[sales_col].sum().reindex(top_idx).fillna(0).sum()
        prev_top = df[prev_mask].groupby(product_col)[sales_col].sum().reindex(top_idx).fillna(0).sum() if prev_mask.any() else None
        if prev_top and prev_top > 0:
            share_change = pct(recent_top, prev_top)
            if share_change < -3:
                reasons.append(f"Top {top_n_products} products declined {share_change:.1f}% (recent vs previous).")

    if not reasons:
        reasons.append("No single dominant reason identified from available columns — check charts/tables.")

    results = {
        'recent_total': recent_total,
        'prev_total': prev_total,
        'pct_change_recent_vs_prev': pct_change_recent_vs_prev,
        'largest_drop': (largest_drop.strftime('%Y-%m'), largest_drop_val) if not pd.isna(largest_drop) else (None, None),
        'product_table': product_table,
        'region_table': region_table,
        'channel_table': channel_table,
        'promo_stats': promo_stats,
        'promo_insights': promo_insights,
        'price_corr': price_corr,
        'price_insights': price_insights,
        'returns_col': returns_col,
        'anomalies': anomalies.to_dict(orient='records'),
        'reasons': reasons,
        'assets': assets,
        'monthly': monthly.reset_index().to_dict(orient='records'),
        'daily_head': daily.reset_index().head(10).to_dict(orient='records')
    }
    return results

# ---------------- GUI ----------------
class SalesApp(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title("Sales Analysis — Minimal UI")
        self.geometry("1000x700")
        self.filename = None
        self.df = None
        self.results = None

        self._build_ui()

        if _missing:
            self.show_missing_packages()

    def _build_ui(self):
        # Top controls
        top = ttk.Frame(self)
        top.pack(fill='x', padx=10, pady=8)
        ttk.Label(top, text="CSV:").pack(side='left')
        self.file_lbl = ttk.Label(top, text="(no file selected)", width=50)
        self.file_lbl.pack(side='left', padx=6)
        ttk.Button(top, text="Open CSV", command=self.open_csv).pack(side='left', padx=6)
        ttk.Button(top, text="Run Analysis", command=self.run_analysis).pack(side='left', padx=6)
        ttk.Button(top, text="Export HTML", command=self.export_html).pack(side='left', padx=6)

        ttk.Label(top, text="Recent months:").pack(side='left', padx=(12,2))
        self.period_var = tk.IntVar(value=3)
        ttk.Spinbox(top, from_=1, to=12, width=4, textvariable=self.period_var).pack(side='left')

        ttk.Label(top, text="Top N products:").pack(side='left', padx=(12,2))
        self.top_var = tk.IntVar(value=10)
        ttk.Spinbox(top, from_=1, to=100, width=4, textvariable=self.top_var).pack(side='left')

        # Status strip
        self.status = ttk.Label(self, text="Ready", relief='sunken', anchor='w')
        self.status.pack(side='bottom', fill='x')

        # Main Paned window
        paned = ttk.Panedwindow(self, orient='horizontal')
        paned.pack(fill='both', expand=True, padx=10, pady=6)

        # Left: summary & tables
        left = ttk.Frame(paned, width=360)
        paned.add(left, weight=1)
        # summary card
        card = ttk.Frame(left, padding=8, relief='ridge')
        card.pack(fill='both', expand=False, pady=(0,8))
        ttk.Label(card, text="Executive summary", font=('TkDefaultFont', 11, 'bold')).pack(anchor='w')
        self.summary_text = tk.Text(card, height=8, wrap='word')
        self.summary_text.pack(fill='both', expand=True, pady=6)
        self.summary_text.configure(state='disabled')

        # tabs for tables
        tabs_left = ttk.Notebook(left)
        tabs_left.pack(fill='both', expand=True)
        self.tab_products = ttk.Frame(tabs_left)
        self.tab_regions = ttk.Frame(tabs_left)
        tabs_left.add(self.tab_products, text="Products")
        tabs_left.add(self.tab_regions, text="Regions / Channels")

        # product tree
        self.prod_tree = ttk.Treeview(self.tab_products, columns=('sales','share'), show='headings')
        self.prod_tree.heading('sales', text='Sales')
        self.prod_tree.heading('share', text='Share%')
        self.prod_tree.pack(fill='both', expand=True)
        # region tree
        self.reg_tree = ttk.Treeview(self.tab_regions, columns=('sales',), show='headings')
        self.reg_tree.heading('sales', text='Sales')
        self.reg_tree.pack(fill='both', expand=True)

        # Right: charts
        right = ttk.Frame(paned)
        paned.add(right, weight=3)
        tabs = ttk.Notebook(right)
        tabs.pack(fill='both', expand=True)
        self.tab_chart1 = ttk.Frame(tabs)
        self.tab_chart2 = ttk.Frame(tabs)
        tabs.add(self.tab_chart1, text="Time Series")
        tabs.add(self.tab_chart2, text="Other Charts")

        # Canvas placeholder for charts
        self.chart_canvas1 = None
        self.chart_canvas2 = None

    def show_missing_packages(self):
        pkgs = ", ".join(_missing)
        pip_cmd = f"pip install {' '.join(_missing)}"
        msg = f"Missing packages: {pkgs}\n\nInstall with:\n    {pip_cmd}\n\nOr use WinPython portable to run this script without system install."
        messagebox.showwarning("Missing packages", msg)

    def open_csv(self):
        f = filedialog.askopenfilename(title="Open sales CSV", filetypes=[("CSV files","*.csv"), ("All files","*.*")])
        if not f:
            return
        self.filename = f
        self.file_lbl.config(text=os.path.basename(f))
        self.status.config(text=f"Loaded: {f}")
        try:
            # attempt to load some rows first
            if pd:
                self.df = pd.read_csv(f)
            else:
                # fallback naive CSV reader into pandas if missing (rare)
                import csv
                with open(f, newline='', encoding='utf-8') as fh:
                    reader = csv.reader(fh)
                    rows = list(reader)
                    hdr = rows[0]
                    data = rows[1:]
                    self.df = pd.DataFrame(data, columns=hdr) if pd else None
            self.status.config(text=f"File loaded: {os.path.basename(f)} ({len(self.df)} rows)")
        except Exception as e:
            messagebox.showerror("Load error", f"Could not load CSV: {e}")
            self.status.config(text="Error loading file")
            self.df = None

    def run_analysis(self):
        if self.df is None:
            messagebox.showinfo("No file", "Please open a CSV file first.")
            return
        if pd is None or np is None or plt is None:
            messagebox.showerror("Missing packages", "pandas, numpy and matplotlib are required. See the pip install instructions.")
            return
        self.status.config(text="Running analysis...")
        self.update_idletasks()
        try:
            self.results = analyze_df(self.df, recent_period_months=int(self.period_var.get()), top_n_products=int(self.top_var.get()))
            self._display_results()
            self.status.config(text="Analysis complete")
        except Exception as e:
            messagebox.showerror("Analysis error", str(e))
            self.status.config(text="Analysis failed")

    def _display_results(self):
        r = self.results
        # summary
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        summary_lines = []
        summary_lines.append(f"Generated: {now}")
        summary_lines.append(f"Recent total: {r['recent_total']:,.2f}")
        if not math.isnan(r['prev_total']):
            summary_lines.append(f"Previous total: {r['prev_total']:,.2f}")
            summary_lines.append(f"Change: {r['pct_change_recent_vs_prev']:.1f}%")
        if r['largest_drop'][0]:
            summary_lines.append(f"Largest month drop: {r['largest_drop'][0]} : {r['largest_drop'][1]:.1f}%")
        summary_lines.append("")
        summary_lines.append("Likely reasons (short):")
        for reason in r['reasons'][:6]:
            summary_lines.append(" - " + reason)
        self.summary_text.configure(state='normal')
        self.summary_text.delete('1.0', 'end')
        self.summary_text.insert('1.0', "\n".join(summary_lines))
        self.summary_text.configure(state='disabled')

        # products table
        for i in self.prod_tree.get_children():
            self.prod_tree.delete(i)
        pt = r.get('product_table')
        if pt and pt.get('top_products'):
            for row in pt['top_products']:
                prod = row.get(pt['product_col'], '')
                sales = float(row.get('sales', 0.0))
                share = float(row.get('share_pct', 0.0))
                self.prod_tree.insert('', 'end', values=(prod, f"{sales:,.2f}", f"{share:.1f}%"))
            # make sure columns match
            self.prod_tree["columns"] = ('product','sales','share')
            self.prod_tree.heading('product', text='Product')
            self.prod_tree.heading('sales', text='Sales')
            self.prod_tree.heading('share', text='Share%')
        else:
            self.prod_tree["columns"] = ('info',)
            self.prod_tree.heading('info', text='Products - no product column found')

        # regions table
        for i in self.reg_tree.get_children():
            self.reg_tree.delete(i)
        rt = r.get('region_table')
        if rt:
            # region_table entries are tuples [ [region, sales], ... ] or dicts depending on grouping
            # normalize
            if isinstance(rt[0], dict):
                # dict like {'region': val, 'sales': val}
                keys = list(rt[0].keys())
                first_region_key = keys[0]
                for row in rt:
                    self.reg_tree.insert('', 'end', values=(row.get(first_region_key,''), f"{row.get('sales',0):,.2f}"))
            else:
                for row in rt:
                    self.reg_tree.insert('', 'end', values=(row[0], f"{row[1]:,.2f}"))
            self.reg_tree["columns"] = ('region','sales')
            self.reg_tree.heading('region', text='Region')
            self.reg_tree.heading('sales', text='Sales')
        else:
            self.reg_tree["columns"] = ('info',)
            self.reg_tree.heading('info', text='No region/channel columns found')

        # charts: embed monthly and daily using TkAgg if available
        # Clear chart frames
        for widget in self.tab_chart1.winfo_children():
            widget.destroy()
        for widget in self.tab_chart2.winfo_children():
            widget.destroy()

        # create matplotlib figures from base64 assets if available
        assets = r.get('assets', {})
        if assets.get('monthly_ts') and FigureCanvasTkAgg is not None:
            try:
                # decode and display images (quick approach)
                from PIL import Image, ImageTk
                b64 = assets['monthly_ts'].split(',',1)[1].encode('ascii')
                im = Image.open(io.BytesIO(base64.b64decode(b64)))
                imtk = ImageTk.PhotoImage(im)
                lbl = ttk.Label(self.tab_chart1, image=imtk)
                lbl.image = imtk
                lbl.pack(fill='both', expand=True)
            except Exception:
                # fallback: try to draw native matplotlib in TkAgg
                try:
                    matplotlib.use("TkAgg")
                    monthly_fig = plt.figure(figsize=(6,3))
                    ax = monthly_fig.add_subplot(111)
                    monthly = pd.DataFrame(r.get('monthly'))
                    ax.bar(pd.to_datetime(monthly['month']), monthly['sales'])
                    ax.set_title("Monthly sales")
                    canvas = FigureCanvasTkAgg(monthly_fig, master=self.tab_chart1)
                    canvas.draw()
                    canvas.get_tk_widget().pack(fill='both', expand=True)
                except Exception:
                    ttk.Label(self.tab_chart1, text="Could not render monthly chart").pack(fill='both', expand=True)
        else:
            ttk.Label(self.tab_chart1, text="No charts available (matplotlib required)").pack(fill='both', expand=True)

        # other charts
        if assets.get('top_products'):
            try:
                from PIL import Image, ImageTk
                b64 = assets['top_products'].split(',',1)[1].encode('ascii')
                im = Image.open(io.BytesIO(base64.b64decode(b64)))
                imtk = ImageTk.PhotoImage(im)
                lbl = ttk.Label(self.tab_chart2, image=imtk)
                lbl.image = imtk
                lbl.pack(fill='both', expand=True)
            except Exception:
                ttk.Label(self.tab_chart2, text="Top-products chart unavailable").pack(fill='both', expand=True)

    def export_html(self):
        if not self.results:
            messagebox.showinfo("Nothing to export", "Please run an analysis first.")
            return
        out = filedialog.asksaveasfilename(defaultextension=".html", filetypes=[("HTML files","*.html")], title="Save report as")
        if not out:
            return
        try:
            html = self._build_html_report()
            with open(out, "w", encoding='utf-8') as f:
                f.write(html)
            messagebox.showinfo("Saved", f"Report saved to {out}")
        except Exception as e:
            messagebox.showerror("Save error", str(e))

    def _build_html_report(self):
        r = self.results
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        assets = r.get('assets', {})
        html = f"""<!doctype html><html><head><meta charset="utf-8"><title>Sales Analysis Report</title>
        <style>body{{font-family:Arial,Helvetica,sans-serif;margin:18px;color:#111}}h1{{font-size:18px}}pre{{background:#f7f7f7;padding:8px}}</style>
        </head><body><h1>Sales Analysis</h1><div>Generated: {now}</div>
        <h2>Executive summary</h2>
        <p>Recent total: {r['recent_total']:,.2f}</p>
        <p>Previous total: {r['prev_total']:,.2f}</p>
        <p>Change: {r['pct_change_recent_vs_prev']:.1f}%</p>
        <h3>Likely reasons</h3><ul>"""
        for reason in r['reasons']:
            html += f"<li>{reason}</li>"
        html += "</ul>"
        if assets.get('monthly_ts'):
            html += f"<h3>Monthly</h3><img src='{assets['monthly_ts']}' style='max-width:100%'>"
        if assets.get('daily_ts'):
            html += f"<h3>Daily</h3><img src='{assets['daily_ts']}' style='max-width:100%'>"
        if r.get('product_table') and r['product_table'].get('top_products'):
            html += "<h3>Top products</h3><table border='1' cellpadding='6'><tr><th>product</th><th>sales</th><th>share%</th></tr>"
            for row in r['product_table']['top_products']:
                name = row.get(r['product_table']['product_col'],'')
                html += f"<tr><td>{name}</td><td>{row.get('sales',0):.2f}</td><td>{row.get('share_pct',0):.1f}</td></tr>"
            html += "</table>"
        html += "<h3>Detailed diagnostics</h3>"
        html += f"<pre>Promotions: {r.get('promo_insights','N/A')}\nPrice corr: {r.get('price_corr')}</pre>"
        html += "</body></html>"
        return html

def main():
    app = SalesApp()
    app.mainloop()

if __name__ == "__main__":
    main()
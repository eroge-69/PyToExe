import pandas as pd
import numpy as np
import dask.dataframe as dd
import tkinter as tk
from tkinter import ttk, filedialog, messagebox, StringVar, Text
from tkinter.ttk import Progressbar, Style
from scipy import stats
from sklearn.ensemble import IsolationForest
from sklearn.cluster import DBSCAN, MiniBatchKMeans
from sklearn.neighbors import LocalOutlierFactor
from sklearn.svm import OneClassSVM
from sklearn.covariance import EllipticEnvelope
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.model_selection import train_test_split
import shap
import plotly.express as px
import plotly.graph_objects as go
import os
import logging
import json
from datetime import datetime
import threading
import time
import webbrowser
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import matplotlib.pyplot as plt
import seaborn as sns
from pandastable import Table
import warnings
from typing import List, Dict, Tuple, Optional, Union
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing as mp
from functools import partial
import joblib
from numba import jit, njit
import psutil


def set_plot_style():
    """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∫—Ä–∞—Å–∏–≤—ã–π —Å—Ç–∏–ª—å –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ matplotlib"""
    available_styles = plt.style.available
    preferred_styles = [
        'seaborn-v0_8',  # –ù–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è seaborn (matplotlib >= 3.6)
        'seaborn',  # –°—Ç–∞—Ä–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        'ggplot',  # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å—Ç–∏–ª—å
        'fivethirtyeight',  # –î—Ä—É–≥–æ–π –ø–æ–ø—É–ª—è—Ä–Ω—ã–π —Å—Ç–∏–ª—å
        'default'  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Å—Ç–∏–ª—å
    ]

    for style in preferred_styles:
        if style in available_styles:
            plt.style.use(style)
            break
    else:
        # –ï—Å–ª–∏ –Ω–∏ –æ–¥–∏–Ω –∏–∑ –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã—Ö —Å—Ç–∏–ª–µ–π –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω
        plt.style.use(available_styles[0] if available_styles else 'default')


# –í—ã–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
set_plot_style()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
warnings.filterwarnings('ignore')
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('anomaly_detector.log'),
        logging.StreamHandler()
    ]
)

# –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è matplotlib
set_plot_style()
sns.set_palette("husl")


class DateTimeEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, (datetime, pd.Timestamp)):
            return obj.isoformat()
        return super().default(obj)


class OptimizedDataProcessor:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""

    @staticmethod
    def optimize_dtypes(df: pd.DataFrame) -> pd.DataFrame:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏"""
        original_memory = df.memory_usage(deep=True).sum() / 1024 ** 2

        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —á–∏—Å–ª–æ–≤—ã—Ö —Ç–∏–ø–æ–≤
        for col in df.select_dtypes(include=['int64']).columns:
            col_min, col_max = df[col].min(), df[col].max()
            if col_min >= np.iinfo(np.int8).min and col_max <= np.iinfo(np.int8).max:
                df[col] = df[col].astype(np.int8)
            elif col_min >= np.iinfo(np.int16).min and col_max <= np.iinfo(np.int16).max:
                df[col] = df[col].astype(np.int16)
            elif col_min >= np.iinfo(np.int32).min and col_max <= np.iinfo(np.int32).max:
                df[col] = df[col].astype(np.int32)

        for col in df.select_dtypes(include=['float64']).columns:
            df[col] = pd.to_numeric(df[col], downcast='float')

        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        for col in df.select_dtypes(include=['object']).columns:
            if df[col].nunique() / len(df) < 0.5:  # –ï—Å–ª–∏ –º–µ–Ω—å—à–µ 50% —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                df[col] = df[col].astype('category')

        optimized_memory = df.memory_usage(deep=True).sum() / 1024 ** 2
        print(f"–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏: {original_memory:.1f}MB -> {optimized_memory:.1f}MB "
              f"({100 * (original_memory - optimized_memory) / original_memory:.1f}% —ç–∫–æ–Ω–æ–º–∏–∏)")

        return df

    @staticmethod
    def stratified_sample(df: pd.DataFrame, sample_size: int = 100000, random_state: int = 42) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É –¥–ª—è –ª—É—á—à–µ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"""
        if len(df) <= sample_size:
            return df

        # –ù–∞—Ö–æ–¥–∏–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
        numeric_cols = df.select_dtypes(include=[np.number]).columns[:5]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 5 –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏

        if len(numeric_cols) == 0:
            return df.sample(n=sample_size, random_state=random_state)

        # –°–æ–∑–¥–∞–µ–º –∫–≤–∞–Ω—Ç–∏–ª–∏ –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
        strata = pd.DataFrame()
        for col in numeric_cols:
            strata[col] = pd.qcut(df[col], q=5, labels=False, duplicates='drop')

        # –°–æ–∑–¥–∞–µ–º —Å–æ—Å—Ç–∞–≤–Ω—É—é —Å—Ç—Ä–∞—Ç—É
        strata['combined'] = strata.apply(lambda x: '_'.join(x.astype(str)), axis=1)
        df_with_strata = df.copy()
        df_with_strata['_strata'] = strata['combined']

        # –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞
        sample_per_stratum = max(1, sample_size // df_with_strata['_strata'].nunique())
        sampled_dfs = []

        for stratum in df_with_strata['_strata'].unique():
            stratum_data = df_with_strata[df_with_strata['_strata'] == stratum]
            n_samples = min(sample_per_stratum, len(stratum_data))
            if n_samples > 0:
                sampled_dfs.append(stratum_data.sample(n=n_samples, random_state=random_state))

        result = pd.concat(sampled_dfs, ignore_index=False)
        return result.drop('_strata', axis=1)

    @staticmethod
    @njit
    def fast_zscore(data: np.ndarray, threshold: float = 3.0) -> np.ndarray:
        """–ë—ã—Å—Ç—Ä–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ Z-score —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Numba"""
        mean = np.mean(data)
        std = np.std(data)
        if std == 0:
            return np.zeros_like(data, dtype=np.bool_)
        z_scores = np.abs((data - mean) / std)
        return z_scores > threshold

    @staticmethod
    @njit
    def fast_iqr(data: np.ndarray) -> np.ndarray:
        """–ë—ã—Å—Ç—Ä–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ IQR –∞–Ω–æ–º–∞–ª–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Numba"""
        q1 = np.percentile(data, 25)
        q3 = np.percentile(data, 75)
        iqr = q3 - q1
        lower = q1 - 1.5 * iqr
        upper = q3 + 1.5 * iqr
        return (data < lower) | (data > upper)


class EnhancedVisuals:
    COLORS = {
        'background': '#f5f7fa',
        'primary': '#4e73df',
        'success': '#1cc88a',
        'info': '#36b9cc',
        'warning': '#f6c23e',
        'danger': '#e74a3b',
        'dark': '#5a5c69',
        'light': '#f8f9fc'
    }

    @staticmethod
    def create_figure(figsize=(8, 6), dpi=100):
        """–°–æ–∑–¥–∞–µ—Ç —Ñ–∏–≥—É—Ä—É matplotlib —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ —Å—Ç–∏–ª—è"""
        fig, ax = plt.subplots(figsize=figsize, dpi=dpi)
        fig.patch.set_facecolor(EnhancedVisuals.COLORS['light'])
        ax.set_facecolor(EnhancedVisuals.COLORS['light'])
        return fig, ax

    @staticmethod
    def scatter_plot(df: pd.DataFrame, anomalies: List, x_col: str, y_col: str, title: str = None):
        """–¢–æ—á–µ—á–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ —Å –≤—ã–¥–µ–ª–µ–Ω–∏–µ–º –∞–Ω–æ–º–∞–ª–∏–π"""
        fig = px.scatter(
            df, x=x_col, y=y_col,
            color=df.index.isin([a[0] for a in anomalies]),
            color_discrete_map={True: EnhancedVisuals.COLORS['danger'], False: EnhancedVisuals.COLORS['primary']},
            hover_data=df.columns.tolist(),
            title=title or f"–ê–Ω–æ–º–∞–ª–∏–∏: {x_col} vs {y_col}",
            template='plotly_white'
        )
        fig.update_layout(
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        return fig

    @staticmethod
    def parallel_coordinates(df: pd.DataFrame, anomalies: List, numeric_cols: List[str], title: str = None):
        """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        fig = px.parallel_coordinates(
            df[numeric_cols],
            color=df.index.isin([a[0] for a in anomalies]),
            color_continuous_scale=[EnhancedVisuals.COLORS['primary'], EnhancedVisuals.COLORS['danger']],
            title=title or "–ú–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π",
            template='plotly_white'
        )
        return fig

    @staticmethod
    def time_series_plot(df: pd.DataFrame, anomalies: List, time_col: str, value_col: str, title: str = None):
        """–ì—Ä–∞—Ñ–∏–∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ —Å –∞–Ω–æ–º–∞–ª–∏—è–º–∏"""
        fig = px.line(
            df, x=time_col, y=value_col,
            title=title or f"–ê–Ω–æ–º–∞–ª–∏–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–∏ ({value_col})",
            template='plotly_white',
            color_discrete_sequence=[EnhancedVisuals.COLORS['primary']]
        )

        anomalies_df = df.loc[[a[0] for a in anomalies]]
        fig.add_trace(
            go.Scatter(
                x=anomalies_df[time_col],
                y=anomalies_df[value_col],
                mode="markers",
                marker=dict(color=EnhancedVisuals.COLORS['danger'], size=10),
                name="–ê–Ω–æ–º–∞–ª–∏–∏"
            )
        )
        fig.update_layout(
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        return fig

    @staticmethod
    def feature_importance_plot(shap_values: np.ndarray, features: List[str], title: str = None):
        """–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —á–µ—Ä–µ–∑ SHAP"""
        fig = go.Figure()
        fig.add_trace(
            go.Bar(
                x=shap_values.mean(0),
                y=features,
                orientation="h",
                marker_color=EnhancedVisuals.COLORS['primary']
            )
        )
        fig.update_layout(
            title=title or "–í–ª–∏—è–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –∞–Ω–æ–º–∞–ª–∏–∏ (SHAP)",
            template='plotly_white',
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        return fig

    @staticmethod
    def show_histogram(df: pd.DataFrame, column: str, anomalies: List = None, bins: int = 30, title: str = None):
        """–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å –≤—ã–¥–µ–ª–µ–Ω–∏–µ–º –∞–Ω–æ–º–∞–ª–∏–π"""
        fig, ax = EnhancedVisuals.create_figure()

        ax.hist(
            df[column],
            bins=bins,
            color=EnhancedVisuals.COLORS['primary'],
            alpha=0.7,
            label='–ù–æ—Ä–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è'
        )

        if anomalies:
            anomaly_values = df.loc[[a[0] for a in anomalies], column]
            ax.hist(
                anomaly_values,
                bins=bins,
                color=EnhancedVisuals.COLORS['danger'],
                alpha=0.7,
                label='–ê–Ω–æ–º–∞–ª–∏–∏'
            )

        ax.set_title(title or f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {column}", fontsize=12)
        ax.set_xlabel(column, fontsize=10)
        ax.set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞', fontsize=10)
        ax.legend()
        ax.grid(True, linestyle='--', alpha=0.6)

        return fig

    @staticmethod
    def show_boxplot(df: pd.DataFrame, column: str, anomalies: List = None, title: str = None):
        """–ë–æ–∫—Å–ø–ª–æ—Ç —Å –≤—ã–¥–µ–ª–µ–Ω–∏–µ–º –∞–Ω–æ–º–∞–ª–∏–π"""
        fig, ax = EnhancedVisuals.create_figure()

        sns.boxplot(
            x=df[column],
            color=EnhancedVisuals.COLORS['primary'],
            width=0.4,
            ax=ax
        )

        if anomalies:
            anomaly_values = df.loc[[a[0] for a in anomalies], column]
            ax.scatter(
                x=anomaly_values,
                y=[0] * len(anomaly_values),
                color=EnhancedVisuals.COLORS['danger'],
                s=50,
                label='–ê–Ω–æ–º–∞–ª–∏–∏'
            )
            ax.legend()

        ax.set_title(title or f"–ë–æ–∫—Å–ø–ª–æ—Ç {column}", fontsize=12)
        ax.set_xlabel(column, fontsize=10)
        ax.grid(True, linestyle='--', alpha=0.6)

        return fig


class OptimizedAnomalyClustering:
    @staticmethod
    def cluster_anomalies(
            df: pd.DataFrame,
            anomalies_indices: List,
            eps: float = 0.5,
            min_samples: int = 5,
            random_state: int = 42,
            use_minibatch: bool = True
    ) -> Dict:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∞–Ω–æ–º–∞–ª–∏–π –≤ –∫–ª–∞—Å—Ç–µ—Ä—ã"""
        anomaly_data = df.loc[anomalies_indices].select_dtypes(include=[np.number])
        anomaly_data = anomaly_data.dropna()

        if anomaly_data.empty:
            logging.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è NaN")
            return {}

        cleaned_indices = anomaly_data.index.tolist()

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º RobustScaler –¥–ª—è –ª—É—á—à–µ–π —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –∫ –≤—ã–±—Ä–æ—Å–∞–º
        scaler = RobustScaler()
        scaled_data = scaler.fit_transform(anomaly_data)

        # –î–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º MiniBatch DBSCAN —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç
        if len(scaled_data) > 10000 and use_minibatch:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º MiniBatchKMeans –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
            n_clusters = min(max(len(scaled_data) // 1000, 5), 50)
            kmeans = MiniBatchKMeans(
                n_clusters=n_clusters,
                batch_size=1000,
                random_state=random_state,
                n_init=3  # –£–º–µ–Ω—å—à–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–π
            )
            clusters = kmeans.fit_predict(scaled_data)
        else:
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π DBSCAN –¥–ª—è –º–µ–Ω—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            clusters = DBSCAN(
                eps=eps,
                min_samples=min_samples,
                metric='euclidean',
                n_jobs=-1  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —è–¥—Ä–∞
            ).fit_predict(scaled_data)

        return dict(zip(cleaned_indices, clusters))

    @staticmethod
    def visualize_clusters(
            df: pd.DataFrame,
            anomalies_indices: List,
            cluster_map: Dict,
            x_col: str,
            y_col: str,
            title: str = None
    ):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∞–Ω–æ–º–∞–ª–∏–π"""
        anomaly_data = df.loc[anomalies_indices]
        anomaly_data['cluster'] = anomaly_data.index.map(cluster_map)

        fig = px.scatter(
            anomaly_data,
            x=x_col,
            y=y_col,
            color='cluster',
            color_discrete_sequence=px.colors.qualitative.Plotly,
            hover_data=df.columns.tolist(),
            title=title or "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π",
            template='plotly_white'
        )

        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏ –±–æ–ª–µ–µ –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º–∏
        normal_data = df[~df.index.isin(anomalies_indices)]
        if len(normal_data) > 10000:  # –ü–æ–¥–≤—ã–±–æ—Ä–∫–∞ –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            normal_data = normal_data.sample(n=10000, random_state=42)

        fig.add_trace(
            go.Scatter(
                x=normal_data[x_col],
                y=normal_data[y_col],
                mode='markers',
                marker=dict(color='gray', opacity=0.2),
                name='–ù–æ—Ä–º–∞–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏',
                hoverinfo='skip'
            )
        )

        fig.update_layout(
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )

        return fig


class ReportGenerator:
    TEMPLATE = """
<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f9f9f9;
        }}
        h1, h2, h3 {{
            color: #2c3e50;
            margin-top: 30px;
        }}
        .header {{
            background-color: #3498db;
            color: white;
            padding: 20px;
            border-radius: 5px;
            margin-bottom: 30px;
            text-align: center;
        }}
        .section {{
            background-color: white;
            padding: 20px;
            border-radius: 5px;
            margin-bottom: 20px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }}
        .anomaly-card {{
            border-left: 4px solid #e74c3c;
            padding: 15px;
            margin-bottom: 15px;
            background-color: #fef5f5;
            border-radius: 0 5px 5px 0;
        }}
        .stats-table {{
            width: 100%;
            border-collapse: collapse;
            margin: 15px 0;
        }}
        .stats-table th, .stats-table td {{
            padding: 10px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }}
        .stats-table th {{
            background-color: #f2f2f2;
        }}
        .highlight {{
            background-color: #fffde7;
            padding: 2px 5px;
            border-radius: 3px;
        }}
        .footer {{
            text-align: center;
            margin-top: 30px;
            color: #7f8c8d;
            font-size: 0.9em;
        }}
    </style>
</head>
<body>
    <div class="header">
        <h1>{title}</h1>
        <p>–û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω {timestamp}</p>
    </div>

    <div class="section">
        <h2>üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞</h2>
        {general_stats}
    </div>

    <div class="section">
        <h2>üîç –î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏</h2>
        <p>–í—Å–µ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ <span class="highlight">{anomaly_count}</span> –∞–Ω–æ–º–∞–ª–∏–π.</p>

        <h3>–¢–æ–ø-10 –∞–Ω–æ–º–∞–ª–∏–π</h3>
        {top_anomalies}
    </div>

    <div class="section">
        <h2>üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º</h2>
        {column_stats}
    </div>

    <div class="footer">
        <p>–û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω Advanced Anomaly Detector | {timestamp}</p>
    </div>
</body>
</html>
"""

    @staticmethod
    def generate_html_report(
            df: pd.DataFrame,
            anomalies: List[Tuple[int, str]],
            filename: str = "anomaly_report.html",
            title: str = "–û—Ç—á–µ—Ç –æ–± –∞–Ω–æ–º–∞–ª–∏—è—Ö"
    ):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫—Ä–∞—Å–∏–≤—ã–π HTML –æ—Ç—á–µ—Ç"""
        timestamp = datetime.now().strftime("%d.%m.%Y %H:%M:%S")

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        general_stats = f"""
        <p>–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: <span class="highlight">{len(df):,}</span></p>
        <p>–í—Å–µ–≥–æ –∫–æ–ª–æ–Ω–æ–∫: <span class="highlight">{len(df.columns)}</span></p>
        <p>–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:</p>
        <ul>
            {"".join(f"<li>{dtype}: {count}</li>" for dtype, count in df.dtypes.value_counts().items())}
        </ul>
        """

        # –¢–æ–ø –∞–Ω–æ–º–∞–ª–∏–π
        top_anomalies = "\n".join(
            f"""
            <div class="anomaly-card">
                <h4>–ê–Ω–æ–º–∞–ª–∏—è #{i + 1} (–°—Ç—Ä–æ–∫–∞ {idx})</h4>
                <pre>{desc}</pre>
            </div>
            """ for i, (idx, desc) in enumerate(anomalies[:10])
        )

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º
        column_stats = ""
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if not numeric_cols.empty:
            stats_df = df[numeric_cols].describe().T
            stats_df['missing'] = df[numeric_cols].isna().mean()
            stats_df['anomaly_count'] = [
                sum(1 for idx, _ in anomalies if col in df.loc[idx].index)
                for col in numeric_cols
            ]

            column_stats = stats_df.to_html(
                classes="stats-table",
                float_format="%.2f",
                border=0
            )

        # –ó–∞–ø–æ–ª–Ω—è–µ–º —à–∞–±–ª–æ–Ω
        report_content = ReportGenerator.TEMPLATE.format(
            title=title,
            timestamp=timestamp,
            general_stats=general_stats,
            anomaly_count=len(anomalies),
            top_anomalies=top_anomalies,
            column_stats=column_stats
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        with open(filename, "w", encoding="utf-8") as f:
            f.write(report_content)

        return filename

    @staticmethod
    def generate_pdf_report(df: pd.DataFrame, anomalies: List[Tuple[int, str]], filename: str):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç PDF –æ—Ç—á–µ—Ç (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç HTML –∫–∞–∫ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —à–∞–≥)"""
        html_file = ReportGenerator.generate_html_report(df, anomalies)
        try:
            import pdfkit
            pdfkit.from_file(html_file, filename)
            return filename
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ PDF: {e}")
            raise


class OptimizedAnomalyDetector:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä –∞–Ω–æ–º–∞–ª–∏–π –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""

    def __init__(self, n_jobs: int = -1):
        self.n_jobs = n_jobs if n_jobs != -1 else mp.cpu_count()
        self.cache = {}

    def _get_optimal_contamination(self, df_size: int) -> float:
        """–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏—è"""
        if df_size < 1000:
            return 0.1
        elif df_size < 10000:
            return 0.05
        elif df_size < 100000:
            return 0.03
        else:
            return 0.01

    def isolation_forest_analysis(self, df_sample: pd.DataFrame, contamination: float = None) -> List[Tuple[int, str]]:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–º Isolation Forest"""
        if contamination is None:
            contamination = self._get_optimal_contamination(len(df_sample))

        numeric_cols = df_sample.select_dtypes(include=[np.number]).columns.tolist()

        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        n_estimators = min(100, max(50, 1000000 // len(df_sample)))
        max_samples = min(256, len(df_sample))

        model = IsolationForest(
            n_estimators=n_estimators,
            max_samples=max_samples,
            contamination=contamination,
            random_state=42,
            n_jobs=self.n_jobs,
            verbose=0,
            warm_start=False
        )

        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        scaler = RobustScaler()
        X_scaled = scaler.fit_transform(df_sample[numeric_cols])

        preds = model.fit_predict(X_scaled)
        scores = model.decision_function(X_scaled)

        anomaly_indices = df_sample[preds == -1].index
        results = []

        for idx in anomaly_indices:
            score_idx = df_sample.index.get_loc(idx)
            row = df_sample.loc[idx]
            report = self._generate_fast_anomaly_report(
                row, df_sample, method="Isolation Forest",
                score=scores[score_idx]
            )
            results.append((idx, report))

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏ (—Å–∞–º—ã–µ –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –ø–µ—Ä–≤—ã–º–∏)
        anomaly_scores = {idx: scores[df_sample.index.get_loc(idx)] for idx in anomaly_indices}
        results.sort(key=lambda x: anomaly_scores[x[0]])

        return results

    def lof_analysis(self, df_sample: pd.DataFrame, contamination: float = None) -> List[Tuple[int, str]]:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–º Local Outlier Factor"""
        if contamination is None:
            contamination = self._get_optimal_contamination(len(df_sample))

        numeric_cols = df_sample.select_dtypes(include=[np.number]).columns.tolist()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ NaN –∏ –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        df_clean = df_sample[numeric_cols].copy()

        # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN –∏–ª–∏ –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        df_clean = df_clean.replace([np.inf, -np.inf], np.nan)
        df_clean = df_clean.dropna()

        if len(df_clean) == 0:
            logging.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ NaN –¥–ª—è LOF –∞–Ω–∞–ª–∏–∑–∞")
            return []

        if len(df_clean) < 10:
            logging.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è LOF –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏")
            return []

        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–æ—Å–µ–¥–µ–π
        n_neighbors = min(20, max(5, len(df_clean) // 100))

        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ n_neighbors –º–µ–Ω—å—à–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
        n_neighbors = min(n_neighbors, len(df_clean) - 1)

        try:
            model = LocalOutlierFactor(
                n_neighbors=n_neighbors,
                contamination=contamination,
                novelty=False,
                n_jobs=self.n_jobs
            )

            scaler = RobustScaler()
            X_scaled = scaler.fit_transform(df_clean)

            preds = model.fit_predict(X_scaled)
            scores = model.negative_outlier_factor_

            anomaly_indices = df_clean[preds == -1].index
            results = []

            for idx in anomaly_indices:
                if idx in df_sample.index:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏–Ω–¥–µ–∫—Å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                    score_idx = df_clean.index.get_loc(idx)
                    row = df_sample.loc[idx]
                    report = self._generate_fast_anomaly_report(
                        row, df_sample, method="Local Outlier Factor",
                        score=scores[score_idx]
                    )
                    results.append((idx, report))

            return results

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –≤ LOF –∞–Ω–∞–ª–∏–∑–µ: {str(e)}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–º–µ—Å—Ç–æ –ø–∞–¥–µ–Ω–∏—è
            return []

    def combined_analysis(self, df_sample: pd.DataFrame) -> List[Tuple[int, str]]:
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤"""
        numeric_cols = df_sample.select_dtypes(include=[np.number]).columns.tolist()
        if not numeric_cols:
            return []

        contamination = self._get_optimal_contamination(len(df_sample))

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ–¥–∏–Ω —Ä–∞–∑
        scaler = RobustScaler()
        X_scaled = scaler.fit_transform(df_sample[numeric_cols])

        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è
        votes = {idx: 0 for idx in df_sample.index}
        all_scores = {idx: [] for idx in df_sample.index}
        method_results = {}

        # 1. Isolation Forest
        print("–ó–∞–ø—É—Å–∫ Isolation Forest...")
        iso_model = IsolationForest(
            n_estimators=min(50, max(25, 100000 // len(df_sample))),
            contamination=contamination,
            random_state=42,
            n_jobs=self.n_jobs
        )
        iso_preds = iso_model.fit_predict(X_scaled)
        iso_scores = iso_model.decision_function(X_scaled)

        for i, idx in enumerate(df_sample.index):
            if iso_preds[i] == -1:
                votes[idx] += 1
                all_scores[idx].append(('iso', abs(iso_scores[i])))

        # 2. Local Outlier Factor (—Ç–æ–ª—å–∫–æ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö < 50k —Å—Ç—Ä–æ–∫ –∏ –±–µ–∑ NaN)
        if len(df_sample) < 50000:
            print("–ó–∞–ø—É—Å–∫ Local Outlier Factor...")
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–ª—è LOF
                df_clean = df_sample[numeric_cols].copy()
                df_clean = df_clean.replace([np.inf, -np.inf], np.nan)
                df_clean = df_clean.dropna()

                if len(df_clean) >= 10:  # –ú–∏–Ω–∏–º—É–º –¥–∞–Ω–Ω—ã—Ö –¥–ª—è LOF
                    lof_model = LocalOutlierFactor(
                        n_neighbors=min(20, len(df_clean) // 50, len(df_clean) - 1),
                        contamination=contamination,
                        n_jobs=self.n_jobs
                    )

                    scaler_lof = RobustScaler()
                    X_scaled_lof = scaler_lof.fit_transform(df_clean)

                    lof_preds = lof_model.fit_predict(X_scaled_lof)
                    lof_scores = lof_model.negative_outlier_factor_

                    for i, idx in enumerate(df_clean.index):
                        if lof_preds[i] == -1 and idx in df_sample.index:
                            votes[idx] += 1
                            all_scores[idx].append(('lof', abs(lof_scores[i])))
                else:
                    print("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è LOF –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏")
            except Exception as e:
                logging.warning(f"LOF –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏: {str(e)}")
                print(f"LOF –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω: {str(e)}")

        # 3. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã (–±—ã—Å—Ç—Ä—ã–µ)
        print("–ó–∞–ø—É—Å–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤...")

        # Z-Score –∞–Ω–∞–ª–∏–∑
        for col in numeric_cols:
            col_data = df_sample[col].values
            z_anomalies = OptimizedDataProcessor.fast_zscore(col_data, threshold=3.0)
            for i, idx in enumerate(df_sample.index):
                if z_anomalies[i]:
                    votes[idx] += 0.5  # –ú–µ–Ω—å—à–∏–π –≤–µ—Å –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤
                    z_score = abs((col_data[i] - np.mean(col_data)) / np.std(col_data))
                    all_scores[idx].append(('zscore', z_score))

        # IQR –∞–Ω–∞–ª–∏–∑
        for col in numeric_cols:
            col_data = df_sample[col].values
            iqr_anomalies = OptimizedDataProcessor.fast_iqr(col_data)
            for i, idx in enumerate(df_sample.index):
                if iqr_anomalies[i]:
                    votes[idx] += 0.5  # –ú–µ–Ω—å—à–∏–π –≤–µ—Å –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤
                    q1, q3 = np.percentile(col_data, [25, 75])
                    iqr = q3 - q1
                    deviation = min(abs(col_data[i] - q1), abs(col_data[i] - q3))
                    all_scores[idx].append(('iqr', deviation / iqr if iqr > 0 else 0))

        # 4. –î–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–æ–±–∞–≤–ª—è–µ–º MiniBatch –ø–æ–¥—Ö–æ–¥
        if len(df_sample) > 100000:
            print("–ó–∞–ø—É—Å–∫ MiniBatch –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏...")
            n_clusters = min(max(len(df_sample) // 5000, 10), 100)
            kmeans = MiniBatchKMeans(
                n_clusters=n_clusters,
                batch_size=min(1000, len(df_sample) // 10),
                random_state=42,
                n_init=3
            )
            clusters = kmeans.fit_predict(X_scaled)
            distances = np.min(kmeans.transform(X_scaled), axis=1)

            # –ë–µ—Ä–µ–º —Ç–æ–ø 5% —Å–∞–º—ã—Ö –¥–∞–ª–µ–∫–∏—Ö —Ç–æ—á–µ–∫
            threshold = np.percentile(distances, 95)
            for i, idx in enumerate(df_sample.index):
                if distances[i] > threshold:
                    votes[idx] += 1
                    all_scores[idx].append(('kmeans', distances[i]))

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–Ω–æ–º–∞–ª–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è
        # –¢—Ä–µ–±—É–µ–º –º–∏–Ω–∏–º—É–º 2 –≥–æ–ª–æ—Å–∞ –¥–ª—è –ø—Ä–∏–∑–Ω–∞–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–µ–π
        min_votes = 2 if len(df_sample) < 10000 else 1.5
        anomaly_candidates = {idx: vote for idx, vote in votes.items() if vote >= min_votes}

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –≥–æ–ª–æ—Å–æ–≤ –∏ —Å–∏–ª–µ –∞–Ω–æ–º–∞–ª–∏–∏
        def anomaly_strength(idx):
            vote_count = votes[idx]
            avg_score = np.mean([score for _, score in all_scores[idx]]) if all_scores[idx] else 0
            return vote_count + avg_score

        sorted_anomalies = sorted(anomaly_candidates.keys(),
                                  key=anomaly_strength, reverse=True)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–Ω–æ–º–∞–ª–∏–π
        max_anomalies = max(len(df_sample) // 100, 100)
        sorted_anomalies = sorted_anomalies[:max_anomalies]

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç—ã
        results = []
        for idx in sorted_anomalies:
            row = df_sample.loc[idx]
            vote_count = votes[idx]
            method_scores = all_scores[idx]

            report = self._generate_combined_anomaly_report(
                row, df_sample, vote_count, method_scores
            )
            results.append((idx, report))

        return results

    def _generate_fast_anomaly_report(
            self,
            row: pd.Series,
            df_sample: pd.DataFrame,
            method: str,
            score: float
    ) -> str:
        """–ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ–± –∞–Ω–æ–º–∞–ª–∏–∏"""
        report = f"üîç –ú–µ—Ç–æ–¥: {method}\n"
        report += f"üìä –ê–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç—å: {abs(score):.3f}\n"
        report += f"üìç –°—Ç—Ä–æ–∫–∞: {row.name}\n\n"

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–µ –æ—Ç–∫–ª–æ–Ω—è—é—â–∏–µ—Å—è –∑–Ω–∞—á–µ–Ω–∏—è
        numeric_cols = df_sample.select_dtypes(include=[np.number]).columns.tolist()
        anomalous_features = []

        for col in numeric_cols[:5]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            val = row[col]
            col_std = df_sample[col].std()
            col_mean = df_sample[col].mean()

            if col_std > 0:
                z_score = abs((val - col_mean) / col_std)
                if z_score > 2:  # –ó–Ω–∞—á–∏–º–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
                    anomalous_features.append((col, val, z_score))

        if anomalous_features:
            report += "üö® –ê–Ω–æ–º–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:\n"
            for col, val, z_score in sorted(anomalous_features, key=lambda x: x[2], reverse=True)[:3]:
                report += f"‚Ä¢ {col}: {val:.2f} (Z-score: {z_score:.2f})\n"

        return report

    def _generate_combined_anomaly_report(
            self,
            row: pd.Series,
            df_sample: pd.DataFrame,
            vote_count: float,
            method_scores: List[Tuple[str, float]]
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –¥–ª—è –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        report = f"üîç –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑\n"
        report += f"üó≥Ô∏è –ì–æ–ª–æ—Å–æ–≤: {vote_count:.1f}\n"
        report += f"üìç –°—Ç—Ä–æ–∫–∞: {row.name}\n\n"

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ—Ç–æ–¥—ã, –∫–æ—Ç–æ—Ä—ã–µ –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏ –∞–Ω–æ–º–∞–ª–∏—é
        if method_scores:
            report += "üìä –ú–µ—Ç–æ–¥—ã –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è:\n"
            method_names = {
                'iso': 'Isolation Forest',
                'lof': 'Local Outlier Factor',
                'zscore': 'Z-Score',
                'iqr': 'IQR',
                'kmeans': 'K-Means clustering'
            }

            grouped_scores = {}
            for method, score in method_scores:
                if method not in grouped_scores:
                    grouped_scores[method] = []
                grouped_scores[method].append(score)

            for method, scores in grouped_scores.items():
                avg_score = np.mean(scores)
                method_name = method_names.get(method, method)
                report += f"‚Ä¢ {method_name}: {avg_score:.3f}\n"

        # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–µ –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        numeric_cols = df_sample.select_dtypes(include=[np.number]).columns.tolist()
        anomalous_features = []

        for col in numeric_cols:
            if col in row.index:
                val = row[col]
                col_std = df_sample[col].std()
                col_mean = df_sample[col].mean()

                if col_std > 0:
                    z_score = abs((val - col_mean) / col_std)
                    if z_score > 1.5:
                        anomalous_features.append((col, val, z_score))

        if anomalous_features:
            report += "\nüö® –ù–∞–∏–±–æ–ª–µ–µ –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:\n"
            for col, val, z_score in sorted(anomalous_features, key=lambda x: x[2], reverse=True)[:5]:
                report += f"‚Ä¢ {col}: {val:.2f} (–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {z_score:.2f}œÉ)\n"

        report += "\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –¢—Ä–µ–±—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è"

        return report


class AdvancedAnomalyDetector:
    METHODS = {
        "Isolation Forest": "–ú–µ—Ç–æ–¥ –∏–∑–æ–ª–∏—Ä—É—é—â–µ–≥–æ –ª–µ—Å–∞ (–±—ã—Å—Ç—Ä—ã–π –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö)",
        "Local Outlier Factor": "–õ–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä –≤—ã–±—Ä–æ—Å–æ–≤ (—Ç–æ—á–Ω—ã–π –¥–ª—è —Å—Ä–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö)",
        "One-Class SVM": "–ú–µ—Ç–æ–¥ –æ–ø–æ—Ä–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ (–º–µ–¥–ª–µ–Ω–Ω—ã–π, –Ω–æ —Ç–æ—á–Ω—ã–π)",
        "Elliptic Envelope": "–≠–ª–ª–∏–ø—Ç–∏—á–µ—Å–∫–∞—è –æ–±–æ–ª–æ—á–∫–∞ (–¥–ª—è –≥–∞—É—Å—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö)",
        "Z-Score": "–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥ (–æ—á–µ–Ω—å –±—ã—Å—Ç—Ä—ã–π)",
        "IQR": "–ú–µ–∂–∫–≤–∞—Ä—Ç–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–∞—Ö (–±—ã—Å—Ç—Ä—ã–π)",
        "Combined": "–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)",
        "Auto": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä (–æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å)"
    }

    def __init__(self, master):
        self.master = master
        self.df = None
        self.original_df = None  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        self.anomalies = []
        self.timer_running = False
        self.timer_id = None
        self.stats_text = None
        self.current_plot = None
        self.shap_values = None
        self.cluster_map = {}
        self.processor = OptimizedDataProcessor()
        self.detector = OptimizedAnomalyDetector()

        # UI variables
        self.mode_var = StringVar(value="local")
        self.method_var = StringVar(value="Combined")
        self.status_var = StringVar(value="–ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
        self.progress_var = tk.IntVar(value=0)

        self._setup_ui()
        self.master.protocol("WM_DELETE_WINDOW", self._on_close)

    def _bind_scroll_to_all_children(self, parent, canvas):
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–∏–≤—è–∑—ã–≤–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è –ø—Ä–æ–∫—Ä—É—Ç–∫–∏ –∫–æ –≤—Å–µ–º –¥–æ—á–µ—Ä–Ω–∏–º —ç–ª–µ–º–µ–Ω—Ç–∞–º"""

        def _on_mousewheel(event):
            canvas.yview_scroll(int(-1 * (event.delta / 120)), "units")

        def _on_mousewheel_linux(event):
            canvas.yview_scroll(-1, "units")

        def _on_mousewheel_linux_up(event):
            canvas.yview_scroll(1, "units")

        # Bind to parent
        parent.bind("<MouseWheel>", _on_mousewheel)  # Windows
        parent.bind("<Button-4>", _on_mousewheel_linux_up)  # Linux
        parent.bind("<Button-5>", _on_mousewheel_linux)  # Linux

        # Recursively bind to all children
        for child in parent.winfo_children():
            child.bind("<MouseWheel>", _on_mousewheel)
            child.bind("<Button-4>", _on_mousewheel_linux_up)
            child.bind("<Button-5>", _on_mousewheel_linux)

            # If child has children, bind recursively
            if child.winfo_children():
                self._bind_scroll_to_all_children(child, canvas)

    def _on_close(self):
        self._stop_timer()
        self.master.destroy()

    def _setup_ui(self):
        self.master.title("Advanced Anomaly Detector v5.1 - Optimized")
        self.master.geometry("1400x900")
        self.master.minsize(1000, 700)

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª–µ–π
        style = Style()
        style.theme_use('clam')

        # –¶–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞
        bg_color = '#f5f7fa'
        primary_color = '#4e73df'
        secondary_color = '#1cc88a'
        accent_color = '#e74a3b'
        text_color = '#5a5c69'

        style.configure('.', background=bg_color, foreground=text_color, font=('Segoe UI', 10))
        style.configure('TFrame', background=bg_color)
        style.configure('TLabel', background=bg_color, foreground=text_color)
        style.configure('Title.TLabel', font=('Segoe UI', 14, 'bold'), foreground=primary_color)
        style.configure('TButton', padding=6, relief='flat', background=primary_color, foreground='white')
        style.map('TButton',
                  background=[('active', primary_color), ('pressed', '#3a56b2')],
                  foreground=[('active', 'white'), ('pressed', 'white')])
        style.configure('Accent.TButton', background=accent_color)
        style.configure('Secondary.TButton', background=secondary_color)
        style.configure('TCombobox', fieldbackground='white', background='white')
        style.configure('TEntry', fieldbackground='white')
        style.configure('TNotebook', background=bg_color)
        style.configure('TNotebook.Tab', padding=[10, 5], font=('Segoe UI', 10, 'bold'))
        style.map('TNotebook.Tab',
                  background=[('selected', bg_color), ('!selected', '#e0e0e0')],
                  foreground=[('selected', primary_color), ('!selected', text_color)])
        style.configure('Treeview',
                        background='white',
                        fieldbackground='white',
                        foreground=text_color,
                        rowheight=25)
        style.map('Treeview', background=[('selected', primary_color)])
        style.configure('Treeview.Heading',
                        background=primary_color,
                        foreground='white',
                        font=('Segoe UI', 10, 'bold'))
        style.configure('Vertical.TScrollbar', background=bg_color)
        style.configure('Horizontal.TScrollbar', background=bg_color)
        style.configure('TProgressbar',
                        thickness=20,
                        troughcolor='#e0e0e0',
                        background=secondary_color)

        # Main container
        main_frame = ttk.Frame(self.master)
        main_frame.pack(fill='both', expand=True, padx=15, pady=15)

        # Header
        header_frame = ttk.Frame(main_frame)
        header_frame.pack(fill='x', pady=(0, 10))

        title_label = ttk.Label(
            header_frame,
            text="–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∞–Ω–æ–º–∞–ª–∏–π (–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)",
            style='Title.TLabel'
        )
        title_label.pack(side='left', padx=10)

        # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.perf_label = ttk.Label(
            header_frame,
            text=f"CPU: {mp.cpu_count()} —è–¥–µ—Ä | RAM: {psutil.virtual_memory().total // (1024 ** 3)}GB",
            font=('Segoe UI', 9)
        )
        self.perf_label.pack(side='right', padx=10)

        ttk.Label(
            header_frame,
            textvariable=self.status_var,
            font=('Segoe UI', 10, 'italic')
        ).pack(side='right', padx=10)

        # Main content
        content_frame = ttk.Frame(main_frame)
        content_frame.pack(fill='both', expand=True)

        # Left panel - controls with scrollbar
        control_canvas = tk.Canvas(content_frame, width=320, bg=bg_color, highlightthickness=0)
        control_scrollbar = ttk.Scrollbar(content_frame, orient="vertical", command=control_canvas.yview)
        control_frame = ttk.Frame(control_canvas, style='TFrame')

        control_frame.bind(
            "<Configure>",
            lambda e: control_canvas.configure(scrollregion=control_canvas.bbox("all"))
        )

        control_canvas.create_window((0, 0), window=control_frame, anchor="nw")
        control_canvas.configure(yscrollcommand=control_scrollbar.set)

        # Bind mouse wheel to canvas
        def _on_mousewheel(event):
            control_canvas.yview_scroll(int(-1 * (event.delta / 120)), "units")

        def _on_mousewheel_linux(event):
            control_canvas.yview_scroll(-1, "units")

        def _on_mousewheel_linux_up(event):
            control_canvas.yview_scroll(1, "units")

        # Bind for different OS
        control_canvas.bind("<MouseWheel>", _on_mousewheel)  # Windows
        control_canvas.bind("<Button-4>", _on_mousewheel_linux_up)  # Linux
        control_canvas.bind("<Button-5>", _on_mousewheel_linux)  # Linux

        # Make sure the canvas can receive focus for scroll events
        control_canvas.bind("<Enter>", lambda e: control_canvas.focus_set())

        # Update scroll region when frame size changes
        def update_scroll_region():
            control_canvas.update_idletasks()
            control_canvas.configure(scrollregion=control_canvas.bbox("all"))

        control_frame.bind("<Configure>", lambda e: update_scroll_region())

        # Pack canvas and scrollbar
        control_canvas.pack(side='left', fill='y', padx=(0, 5))
        control_scrollbar.pack(side='left', fill='y', padx=(0, 10))

        # Data loading section
        data_frame = ttk.LabelFrame(control_frame, text="üìÅ –î–∞–Ω–Ω—ã–µ", padding=10)
        data_frame.pack(fill='x', pady=(0, 10))

        ttk.Button(
            data_frame,
            text="–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ",
            command=self._load_data,
            style='TButton',
            cursor='hand2'
        ).pack(fill='x', pady=5)

        ttk.Button(
            data_frame,
            text="–ü—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å –¥–∞–Ω–Ω—ã–µ",
            command=self._preview_data,
            style='Secondary.TButton',
            cursor='hand2'
        ).pack(fill='x', pady=5)

        # Optimization section
        opt_frame = ttk.LabelFrame(control_frame, text="‚ö° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è", padding=10)
        opt_frame.pack(fill='x', pady=(0, 10))

        self.optimize_memory_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(
            opt_frame,
            text="–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏",
            variable=self.optimize_memory_var,
            cursor='hand2'
        ).pack(anchor='w', pady=2)

        self.use_sampling_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(
            opt_frame,
            text="–£–º–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞",
            variable=self.use_sampling_var,
            cursor='hand2'
        ).pack(anchor='w', pady=2)

        self.parallel_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(
            opt_frame,
            text="–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è",
            variable=self.parallel_var,
            cursor='hand2'
        ).pack(anchor='w', pady=2)

        # Analysis settings
        analysis_frame = ttk.LabelFrame(control_frame, text="‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω–∞–ª–∏–∑–∞", padding=10)
        analysis_frame.pack(fill='x', pady=(0, 10))

        ttk.Label(analysis_frame, text="–ú–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞:").pack(anchor='w', pady=(0, 5))
        method_combo = ttk.Combobox(
            analysis_frame,
            textvariable=self.method_var,
            values=list(self.METHODS.keys()),
            state="readonly",
            cursor='hand2'
        )
        method_combo.pack(fill='x', pady=(0, 10))
        method_combo.bind("<<ComboboxSelected>>", self._show_method_info)

        # Info label for method description
        self.method_info = ttk.Label(
            analysis_frame,
            text=self.METHODS[self.method_var.get()],
            wraplength=280,
            justify='left',
            foreground='#666'
        )
        self.method_info.pack(fill='x', pady=5)

        ttk.Button(
            analysis_frame,
            text="–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å",
            command=self._start_analysis,
            style='Accent.TButton',
            cursor='hand2'
        ).pack(fill='x', pady=10)

        # Progress bar
        progress_frame = ttk.Frame(control_frame)
        progress_frame.pack(fill='x', pady=(0, 10))

        ttk.Label(progress_frame, text="–ü—Ä–æ–≥—Ä–µ—Å—Å:").pack(anchor='w')
        self.progress = Progressbar(
            progress_frame,
            orient="horizontal",
            length=280,
            variable=self.progress_var,
            style='TProgressbar'
        )
        self.progress.pack(fill='x', pady=5)

        self.timer_label = ttk.Label(progress_frame, text="–í—Ä–µ–º—è: 00:00")
        self.timer_label.pack(pady=5)

        # Performance info
        self.perf_info = ttk.Label(progress_frame, text="", font=('Segoe UI', 8))
        self.perf_info.pack(pady=2)

        # Visualization section
        viz_frame = ttk.LabelFrame(control_frame, text="üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è", padding=10)
        viz_frame.pack(fill='x', pady=(0, 10))

        ttk.Button(
            viz_frame,
            text="–¢–æ—á–µ—á–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫",
            command=self._show_scatter_plot,
            cursor='hand2'
        ).pack(fill='x', pady=2)

        ttk.Button(
            viz_frame,
            text="–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã",
            command=self._show_parallel_coords,
            cursor='hand2'
        ).pack(fill='x', pady=2)

        ttk.Button(
            viz_frame,
            text="–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥",
            command=self._show_time_series,
            cursor='hand2'
        ).pack(fill='x', pady=2)

        ttk.Button(
            viz_frame,
            text="–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞",
            command=self._show_histogram,
            cursor='hand2'
        ).pack(fill='x', pady=2)

        ttk.Button(
            viz_frame,
            text="–ë–æ–∫—Å–ø–ª–æ—Ç",
            command=self._show_boxplot,
            cursor='hand2'
        ).pack(fill='x', pady=2)

        ttk.Button(
            viz_frame,
            text="–ö–ª–∞—Å—Ç–µ—Ä—ã –∞–Ω–æ–º–∞–ª–∏–π",
            command=self._show_clusters,
            cursor='hand2'
        ).pack(fill='x', pady=2)

        # Export section
        export_frame = ttk.LabelFrame(control_frame, text="üíæ –≠–∫—Å–ø–æ—Ä—Ç", padding=10)
        export_frame.pack(fill='x')

        ttk.Button(
            export_frame,
            text="–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
            command=self._export_results,
            cursor='hand2'
        ).pack(fill='x', pady=2)

        ttk.Button(
            export_frame,
            text="HTML –æ—Ç—á–µ—Ç",
            command=lambda: self._generate_report("html"),
            style='Secondary.TButton',
            cursor='hand2'
        ).pack(fill='x', pady=2)

        ttk.Button(
            export_frame,
            text="PDF –æ—Ç—á–µ—Ç",
            command=lambda: self._generate_report("pdf"),
            style='Secondary.TButton',
            cursor='hand2'
        ).pack(fill='x', pady=2)

        # Right panel - results
        notebook = ttk.Notebook(content_frame)
        notebook.pack(side='right', fill='both', expand=True)

        # Anomalies table tab
        table_frame = ttk.Frame(notebook)
        self._setup_table(table_frame)
        notebook.add(table_frame, text="–ê–Ω–æ–º–∞–ª–∏–∏")

        # Details tab
        details_frame = ttk.Frame(notebook)
        self._setup_details(details_frame)
        notebook.add(details_frame, text="–î–µ—Ç–∞–ª–∏")

        # Stats tab
        stats_frame = ttk.Frame(notebook)
        self._setup_stats(stats_frame)
        notebook.add(stats_frame, text="–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")

        # Visualization tab
        self.plot_frame = ttk.Frame(notebook)
        notebook.add(self.plot_frame, text="–ì—Ä–∞—Ñ–∏–∫–∏")

        # Status bar
        status_frame = ttk.Frame(main_frame, height=25)
        status_frame.pack(fill='x', padx=10, pady=(5, 0))

        ttk.Label(
            status_frame,
            text="Advanced Anomaly Detector v5.1 - Optimized | ¬© 2023",
            font=('Segoe UI', 8)
        ).pack(side='left')

        ttk.Label(
            status_frame,
            textvariable=self.status_var,
            font=('Segoe UI', 8),
            relief="sunken",
            padding=(5, 0)
        ).pack(side='right')

        # Bind scroll events to all widgets in control frame
        self._bind_scroll_to_all_children(control_frame, control_canvas)

    def _show_method_info(self, event=None):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞"""
        method = self.method_var.get()
        self.method_info.config(text=self.METHODS.get(method, "–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ"))

    def _setup_table(self, parent):
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π"""
        # Treeview with scrollbars
        tree_frame = ttk.Frame(parent)
        tree_frame.pack(fill='both', expand=True, padx=5, pady=5)

        self.tree = ttk.Treeview(tree_frame, selectmode='browse')

        scroll_y = ttk.Scrollbar(tree_frame, orient="vertical", command=self.tree.yview)
        scroll_x = ttk.Scrollbar(tree_frame, orient="horizontal", command=self.tree.xview)

        self.tree.configure(yscrollcommand=scroll_y.set, xscrollcommand=scroll_x.set)

        # Layout
        self.tree.grid(row=0, column=0, sticky='nsew')
        scroll_y.grid(row=0, column=1, sticky='ns')
        scroll_x.grid(row=1, column=0, sticky='ew')

        tree_frame.grid_rowconfigure(0, weight=1)
        tree_frame.grid_columnconfigure(0, weight=1)

        # Columns
        self.tree["columns"] = ("row_id", "anomaly_type", "score", "cluster")
        self.tree.heading("#0", text="#", anchor='w')
        self.tree.heading("row_id", text="–°—Ç—Ä–æ–∫–∞", anchor='w')
        self.tree.heading("anomaly_type", text="–¢–∏–ø –∞–Ω–æ–º–∞–ª–∏–∏", anchor='w')
        self.tree.heading("score", text="–°–∏–ª–∞", anchor='w')
        self.tree.heading("cluster", text="–ö–ª–∞—Å—Ç–µ—Ä", anchor='w')

        self.tree.column("#0", width=50, minwidth=50)
        self.tree.column("row_id", width=80, minwidth=80)
        self.tree.column("anomaly_type", width=120, minwidth=100)
        self.tree.column("score", width=60, minwidth=60)
        self.tree.column("cluster", width=80, minwidth=60)

        # Bind selection event
        self.tree.bind("<<TreeviewSelect>>", lambda e: self._show_anomaly_details())

    def _setup_details(self, parent):
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ø–∞–Ω–µ–ª—å –¥–µ—Ç–∞–ª–µ–π –∞–Ω–æ–º–∞–ª–∏–∏"""
        details_frame = ttk.Frame(parent)
        details_frame.pack(fill='both', expand=True, padx=5, pady=5)

        self.details_text = Text(
            details_frame,
            wrap="word",
            padx=10,
            pady=10,
            font=('Consolas', 10),
            bg='white',
            fg='#333'
        )

        scroll = ttk.Scrollbar(details_frame, command=self.details_text.yview)
        self.details_text.configure(yscrollcommand=scroll.set)

        # Layout
        self.details_text.pack(side='left', fill='both', expand=True)
        scroll.pack(side='right', fill='y')

    def _setup_stats(self, parent):
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ø–∞–Ω–µ–ª—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        stats_frame = ttk.Frame(parent)
        stats_frame.pack(fill='both', expand=True, padx=5, pady=5)

        self.stats_text = Text(
            stats_frame,
            wrap="word",
            padx=10,
            pady=10,
            font=('Consolas', 10),
            bg='white',
            fg='#333'
        )

        scroll = ttk.Scrollbar(stats_frame, command=self.stats_text.yview)
        self.stats_text.configure(yscrollcommand=scroll.set)

        # Layout
        self.stats_text.pack(side='left', fill='both', expand=True)
        scroll.pack(side='right', fill='y')

    def _clear_plot_frame(self):
        """–û—á–∏—â–∞–µ—Ç —Ñ—Ä–µ–π–º –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤"""
        for widget in self.plot_frame.winfo_children():
            widget.destroy()

    def _show_plot(self, fig):
        """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫ matplotlib –≤–æ —Ñ—Ä–µ–π–º–µ"""
        self._clear_plot_frame()

        if isinstance(fig, go.Figure):
            # –î–ª—è Plotly —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ HTML –∏ –æ—Ç–∫—Ä—ã–≤–∞–µ–º –≤ –±—Ä–∞—É–∑–µ—Ä–µ
            html_file = os.path.join(os.getcwd(), "temp_plot.html")
            fig.write_html(html_file, auto_open=True)
        else:
            # –î–ª—è matplotlib —Å–æ–∑–¥–∞–µ–º canvas
            canvas = FigureCanvasTkAgg(fig, master=self.plot_frame)
            canvas.draw()
            canvas.get_tk_widget().pack(fill='both', expand=True)

            # Add toolbar
            from matplotlib.backends.backend_tkagg import NavigationToolbar2Tk
            toolbar = NavigationToolbar2Tk(canvas, self.plot_frame)
            toolbar.update()
            canvas._tkcanvas.pack(fill='both', expand=True)

            self.current_plot = canvas

    def _preview_data(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –æ–∫–Ω–µ"""
        if self.df is None:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ")
            return

        try:
            preview_window = tk.Toplevel(self.master)
            preview_window.title("–ü—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
            preview_window.geometry("1000x600")
            preview_window.state('normal')

            # –°–æ–∑–¥–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ—Ä–µ–π–º
            main_frame = ttk.Frame(preview_window)
            main_frame.pack(fill='both', expand=True, padx=10, pady=10)

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö
            info_frame = ttk.Frame(main_frame)
            info_frame.pack(fill='x', pady=(0, 10))

            info_text = f"–î–∞–Ω–Ω—ã–µ: {len(self.df):,} —Å—Ç—Ä–æ–∫ √ó {len(self.df.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤"
            ttk.Label(info_frame, text=info_text, font=('Segoe UI', 12, 'bold')).pack()

            # –°–æ–∑–¥–∞–µ–º Treeview –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
            tree_frame = ttk.Frame(main_frame)
            tree_frame.pack(fill='both', expand=True)

            # Treeview —Å –ø—Ä–æ–∫—Ä—É—Ç–∫–æ–π
            tree = ttk.Treeview(tree_frame, show='headings')

            # Scrollbars
            v_scrollbar = ttk.Scrollbar(tree_frame, orient="vertical", command=tree.yview)
            h_scrollbar = ttk.Scrollbar(tree_frame, orient="horizontal", command=tree.xview)

            tree.configure(yscrollcommand=v_scrollbar.set, xscrollcommand=h_scrollbar.set)

            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ (–æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 20 –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
            display_cols = list(self.df.columns)[:20]
            tree["columns"] = display_cols

            for col in display_cols:
                tree.heading(col, text=col)
                tree.column(col, width=120, minwidth=80)

            # –ó–∞–ø–æ–ª–Ω—è–µ–º –¥–∞–Ω–Ω—ã–º–∏ (–ø–µ—Ä–≤—ã–µ 1000 —Å—Ç—Ä–æ–∫ –¥–ª—è –±—ã—Å—Ç—Ä–æ–¥–µ–π—Å—Ç–≤–∏—è)
            display_rows = min(1000, len(self.df))
            for i in range(display_rows):
                row_data = []
                for col in display_cols:
                    val = self.df.iloc[i][col]
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    if pd.isna(val):
                        formatted_val = "NaN"
                    elif isinstance(val, float):
                        formatted_val = f"{val:.3f}" if abs(val) < 1000 else f"{val:.2e}"
                    else:
                        formatted_val = str(val)[:50]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                    row_data.append(formatted_val)

                tree.insert("", "end", values=row_data)

            # –†–∞–∑–º–µ—â–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã
            tree.grid(row=0, column=0, sticky='nsew')
            v_scrollbar.grid(row=0, column=1, sticky='ns')
            h_scrollbar.grid(row=1, column=0, sticky='ew')

            tree_frame.grid_rowconfigure(0, weight=1)
            tree_frame.grid_columnconfigure(0, weight=1)

            # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            button_frame = ttk.Frame(main_frame)
            button_frame.pack(fill='x', pady=(10, 0))

            if len(self.df.columns) > 20:
                ttk.Label(
                    button_frame,
                    text=f"–ü–æ–∫–∞–∑–∞–Ω—ã –ø–µ—Ä–≤—ã–µ 20 –∏–∑ {len(self.df.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤",
                    foreground='gray'
                ).pack(side='left')

            if len(self.df) > 1000:
                ttk.Label(
                    button_frame,
                    text=f"–ü–æ–∫–∞–∑–∞–Ω—ã –ø–µ—Ä–≤—ã–µ 1000 –∏–∑ {len(self.df):,} —Å—Ç—Ä–æ–∫",
                    foreground='gray'
                ).pack(side='right')

            ttk.Button(
                button_frame,
                text="–ó–∞–∫—Ä—ã—Ç—å",
                command=preview_window.destroy,
                cursor='hand2'
            ).pack(side='bottom', pady=5)

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–∞–Ω–Ω—ã–º
            stats_frame = ttk.LabelFrame(main_frame, text="–ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", padding=5)
            stats_frame.pack(fill='x', pady=(10, 0))

            numeric_cols = self.df.select_dtypes(include=[np.number]).columns
            stats_text = f"–ß–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤: {len(numeric_cols)}\n"

            if len(numeric_cols) > 0:
                stats_text += f"–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {self.df[numeric_cols].isna().sum().sum():,}\n"
                stats_text += f"–î—É–±–ª–∏–∫–∞—Ç–æ–≤: {self.df.duplicated().sum():,}"

            ttk.Label(stats_frame, text=stats_text, justify='left').pack(anchor='w')

            # –û–±–Ω–æ–≤–ª—è–µ–º –æ–∫–Ω–æ
            preview_window.focus()

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {str(e)}", exc_info=True)
            messagebox.showerror("–û—à–∏–±–∫–∞", f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ:\n{str(e)}")

    def _load_data(self):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞"""
        file_path = filedialog.askopenfilename(
            title="–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏",
            filetypes=[
                ("–î–∞–Ω–Ω—ã–µ", "*.tsv;*.csv;*.xlsx;*.parquet;*.feather"),
                ("TSV —Ñ–∞–π–ª—ã", "*.tsv"),
                ("CSV —Ñ–∞–π–ª—ã", "*.csv"),
                ("Excel —Ñ–∞–π–ª—ã", "*.xlsx"),
                ("Parquet —Ñ–∞–π–ª—ã", "*.parquet"),
                ("–í—Å–µ —Ñ–∞–π–ª—ã", "*.*")
            ]
        )

        if not file_path:
            return

        try:
            start_time = time.time()
            self.status_var.set("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
            self.progress_var.set(0)
            self.master.update()

            file_ext = os.path.splitext(file_path)[1].lower()
            file_size = os.path.getsize(file_path) / (1024 * 1024)  # –≤ MB

            self.status_var.set(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ ({file_size:.1f} MB)...")
            self.progress_var.set(10)

            # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
            if file_size > 500:  # –û—á–µ–Ω—å –±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã
                self.status_var.set("–ó–∞–≥—Ä—É–∑–∫–∞ –±–æ–ª—å—à–æ–≥–æ —Ñ–∞–π–ª–∞ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π...")
                if file_ext == '.tsv':
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —á–∞–Ω–∫–∏ –¥–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
                    chunks = []
                    for chunk in pd.read_csv(file_path, sep='\t', chunksize=50000, encoding='utf-8'):
                        chunks.append(chunk)
                        if len(chunks) * 50000 > 1000000:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 1M —Å—Ç—Ä–æ–∫
                            break
                    self.df = pd.concat(chunks, ignore_index=True)
                elif file_ext == '.parquet':
                    self.df = pd.read_parquet(file_path)
                else:
                    chunks = []
                    for chunk in pd.read_csv(file_path, chunksize=50000):
                        chunks.append(chunk)
                        if len(chunks) * 50000 > 1000000:
                            break
                    self.df = pd.concat(chunks, ignore_index=True)
            elif file_size > 100:  # –ë–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã
                self.status_var.set(f"–ó–∞–≥—Ä—É–∑–∫–∞ –±–æ–ª—å—à–æ–≥–æ —Ñ–∞–π–ª–∞ ({file_size:.1f} MB)...")
                if file_ext == '.tsv':
                    self.df = pd.read_csv(file_path, sep='\t', encoding='utf-8')
                elif file_ext == '.csv':
                    self.df = pd.read_csv(file_path)
                elif file_ext == '.xlsx':
                    self.df = pd.read_excel(file_path, engine='openpyxl')
                elif file_ext == '.parquet':
                    self.df = pd.read_parquet(file_path)
                elif file_ext == '.feather':
                    self.df = pd.read_feather(file_path)
            else:
                # –î–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É
                if file_ext == '.tsv':
                    self.df = pd.read_csv(file_path, sep='\t', encoding='utf-8')
                elif file_ext == '.csv':
                    self.df = pd.read_csv(file_path)
                elif file_ext == '.xlsx':
                    self.df = pd.read_excel(file_path)
                elif file_ext == '.parquet':
                    self.df = pd.read_parquet(file_path)
                elif file_ext == '.feather':
                    self.df = pd.read_feather(file_path)

            self.progress_var.set(50)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            self.original_df = self.df.copy()

            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞—Ç
            self.status_var.set("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç...")
            date_cols = [col for col in self.df.columns
                         if 'date' in col.lower() or 'time' in col.lower()]
            for col in date_cols:
                try:
                    self.df[col] = pd.to_datetime(self.df[col], errors='coerce')
                except:
                    continue

            self.progress_var.set(70)

            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞
            if self.optimize_memory_var.get():
                self.status_var.set("–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏...")
                self.df = self.processor.optimize_dtypes(self.df)

            self.progress_var.set(90)

            load_time = time.time() - start_time
            self.status_var.set(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(self.df):,} —Å—Ç—Ä–æ–∫, {len(self.df.columns)} –∫–æ–ª–æ–Ω–æ–∫ ({load_time:.1f}—Å)")

            # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            memory_usage = self.df.memory_usage(deep=True).sum() / (1024 ** 2)
            self.perf_info.config(text=f"–ü–∞–º—è—Ç—å: {memory_usage:.1f}MB | –í—Ä–µ–º—è: {load_time:.1f}—Å")

            messagebox.showinfo("–£—Å–ø–µ—Ö",
                                f"–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\n\n–°—Ç—Ä–æ–∫: {len(self.df):,}\n–°—Ç–æ–ª–±—Ü–æ–≤: {len(self.df.columns)}\n–í—Ä–µ–º—è: {load_time:.1f}—Å")

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}", exc_info=True)
            messagebox.showerror("–û—à–∏–±–∫–∞", f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª:\n{str(e)}")
            self.status_var.set("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏")
        finally:
            self.progress_var.set(100)
            time.sleep(0.5)
            self.progress_var.set(0)

    def _start_timer(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ç–∞–π–º–µ—Ä –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        self.start_time = time.time()
        self.timer_running = True
        self._update_timer()

    def _stop_timer(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ç–∞–π–º–µ—Ä"""
        self.timer_running = False
        if self.timer_id:
            self.master.after_cancel(self.timer_id)

    def _update_timer(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–∞–π–º–µ—Ä–∞"""
        if not self.timer_running:
            return

        elapsed = time.time() - self.start_time
        mins, secs = divmod(int(elapsed), 60)
        self.timer_label.config(text=f"–í—Ä–µ–º—è: {mins:02d}:{secs:02d}")

        # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ—Å—É—Ä—Å–∞—Ö
        cpu_percent = psutil.cpu_percent(interval=None)
        memory_percent = psutil.virtual_memory().percent
        self.perf_info.config(text=f"CPU: {cpu_percent:.1f}% | RAM: {memory_percent:.1f}%")

        self.timer_id = self.master.after(1000, self._update_timer)

    def _start_analysis(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
        if self.df is None:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ")
            return

        try:
            self.status_var.set("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∞–Ω–∞–ª–∏–∑–∞...")
            self.progress_var.set(0)
            self._start_timer()

            # –ó–∞–ø—É—Å–∫ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            threading.Thread(
                target=self._run_optimized_analysis,
                daemon=True
            ).start()

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}", exc_info=True)
            messagebox.showerror("–û—à–∏–±–∫–∞", f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞:\n{str(e)}")
            self._stop_timer()
            self.progress_var.set(0)

    def _run_optimized_analysis(self):
        """–û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            analysis_start = time.time()

            # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            self.status_var.set("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
            self.progress_var.set(5)

            df_for_analysis = self._prepare_optimized_sample()
            if df_for_analysis is None:
                return

            data_prep_time = time.time() - analysis_start
            self.status_var.set(f"–î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã ({data_prep_time:.1f}—Å)")
            self.progress_var.set(20)

            # 2. –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞
            analysis_time = time.time()
            self.status_var.set("–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞...")

            method = self.method_var.get()
            results = self._analyze_optimized_data(df_for_analysis, method)

            analysis_duration = time.time() - analysis_time
            self.status_var.set(f"–ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω ({analysis_duration:.1f}—Å)")
            self.progress_var.set(60)

            # 3. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
            if results and len(results) > 10:
                cluster_time = time.time()
                self.status_var.set("–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π...")
                self.progress_var.set(70)

                anomalies_indices = [a[0] for a in results][:5000]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                if anomalies_indices:
                    self.cluster_map = OptimizedAnomalyClustering.cluster_anomalies(
                        df_for_analysis,
                        anomalies_indices,
                        eps='auto' if len(anomalies_indices) < 1000 else 0.5,
                        min_samples=5,
                        use_minibatch=len(anomalies_indices) > 1000
                    )

                    # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö
                    for i, (idx, desc) in enumerate(results[:5000]):
                        cluster = self.cluster_map.get(idx, -1)
                        cluster_info = f"–ö–ª–∞—Å—Ç–µ—Ä {cluster}" if cluster != -1 else "–ï–¥–∏–Ω–∏—á–Ω–∞—è"
                        results[i] = (idx, f"{desc}\n\nüî∑ {cluster_info}\n")

                cluster_duration = time.time() - cluster_time
                self.status_var.set(f"–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ ({cluster_duration:.1f}—Å)")

            # 4. –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            self.progress_var.set(80)
            self.status_var.set("–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")

            self.anomalies = results
            self._generate_optimized_stats_report(df_for_analysis)
            self._display_optimized_results()

            total_time = time.time() - analysis_start

            self.status_var.set(f"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω ({total_time:.1f}—Å). –ù–∞–π–¥–µ–Ω–æ {len(self.anomalies)} –∞–Ω–æ–º–∞–ª–∏–π")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            perf_stats = (f"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!\n\n"
                          f"–í—Ä–µ–º—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏: {data_prep_time:.1f}—Å\n"
                          f"–í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {analysis_duration:.1f}—Å\n"
                          f"–û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.1f}—Å\n"
                          f"–ù–∞–π–¥–µ–Ω–æ –∞–Ω–æ–º–∞–ª–∏–π: {len(self.anomalies)}\n"
                          f"–°–∫–æ—Ä–æ—Å—Ç—å: {len(df_for_analysis) / total_time:.0f} —Å—Ç—Ä–æ–∫/—Å")

            messagebox.showinfo("–ì–æ—Ç–æ–≤–æ", perf_stats)

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}", exc_info=True)
            messagebox.showerror("–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞", str(e))
            self.status_var.set("–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞")
        finally:
            self.progress_var.set(100)
            self._stop_timer()

    def _prepare_optimized_sample(self) -> Optional[pd.DataFrame]:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        if self.df is None or self.df.empty:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return None

        df_sample = self.df.copy()

        # –í—ã–±–æ—Ä —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        numeric_cols = df_sample.select_dtypes(include=[np.number]).columns.tolist()
        if not numeric_cols:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–ù–µ –Ω–∞–π–¥–µ–Ω—ã —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return None

        # –£–º–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        if self.use_sampling_var.get() and len(df_sample) > 100000:
            sample_size = min(100000, len(df_sample))
            if len(df_sample) > 1000000:
                sample_size = min(200000, len(df_sample))

            self.status_var.set(f"–°–æ–∑–¥–∞–Ω–∏–µ —É–º–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ ({sample_size:,} –∏–∑ {len(df_sample):,})...")
            df_sample = self.processor.stratified_sample(df_sample, sample_size)

        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        for col in numeric_cols:
            if df_sample[col].isna().any() or np.isinf(df_sample[col]).any():
                # –ó–∞–º–µ–Ω—è–µ–º –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ NaN
                df_sample[col] = df_sample[col].replace([np.inf, -np.inf], np.nan)

                if len(df_sample) > 100000:
                    # –î–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º –±—ã—Å—Ç—Ä—ã–µ –º–µ—Ç–æ–¥—ã
                    median_val = df_sample[col].median()
                    df_sample[col].fillna(median_val, inplace=True)
                else:
                    # –î–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö - –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã
                    df_sample[col].interpolate(method='linear', inplace=True, limit_direction='both')
                    median_val = df_sample[col].median()
                    df_sample[col].fillna(median_val, inplace=True)

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ NaN –∏–ª–∏ –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        df_sample = df_sample.replace([np.inf, -np.inf], np.nan)
        df_sample = df_sample.dropna()

        if len(df_sample) == 0:
            messagebox.showerror("–û—à–∏–±–∫–∞", "–ù–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏")
            return None

        return df_sample

    def _analyze_optimized_data(self, df_sample: pd.DataFrame, method: str) -> List[Tuple[int, str]]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –≤—ã–±—Ä–∞–Ω–Ω—ã–º –º–µ—Ç–æ–¥–æ–º"""
        if not self.parallel_var.get():
            self.detector.n_jobs = 1

        if method == "Isolation Forest":
            return self.detector.isolation_forest_analysis(df_sample)
        elif method == "Local Outlier Factor":
            return self.detector.lof_analysis(df_sample)
        elif method == "One-Class SVM":
            return self._svm_analysis(df_sample)
        elif method == "Elliptic Envelope":
            return self._elliptic_envelope_analysis(df_sample)
        elif method == "Z-Score":
            return self._fast_zscore_analysis(df_sample)
        elif method == "IQR":
            return self._fast_iqr_analysis(df_sample)
        elif method == "Combined":
            return self.detector.combined_analysis(df_sample)
        else:  # Auto
            return self._auto_optimized_analysis(df_sample)

    def _fast_zscore_analysis(self, df_sample: pd.DataFrame) -> List[Tuple[int, str]]:
        """–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–º Z-Score —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Numba"""
        results = []
        numeric_cols = df_sample.select_dtypes(include=[np.number]).columns.tolist()

        for col in numeric_cols:
            col_data = df_sample[col].values
            anomaly_mask = OptimizedDataProcessor.fast_zscore(col_data, threshold=3.0)

            for i, is_anomaly in enumerate(anomaly_mask):
                if is_anomaly:
                    idx = df_sample.index[i]
                    row = df_sample.loc[idx]
                    z_score = abs((col_data[i] - np.mean(col_data)) / np.std(col_data))

                    report = (f"üîç –ú–µ—Ç–æ–¥: Z-Score (–±—ã—Å—Ç—Ä—ã–π)\n"
                              f"üìä Z-Score: {z_score:.3f}\n"
                              f"üìç –°—Ç—Ä–æ–∫–∞: {idx}\n"
                              f"üö® –ê–Ω–æ–º–∞–ª—å–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞: {col} = {col_data[i]:.2f}\n")

                    results.append((idx, report))

        return results

    def _fast_iqr_analysis(self, df_sample: pd.DataFrame) -> List[Tuple[int, str]]:
        """–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–º IQR —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Numba"""
        results = []
        numeric_cols = df_sample.select_dtypes(include=[np.number]).columns.tolist()

        for col in numeric_cols:
            col_data = df_sample[col].values
            anomaly_mask = OptimizedDataProcessor.fast_iqr(col_data)

            for i, is_anomaly in enumerate(anomaly_mask):
                if is_anomaly:
                    idx = df_sample.index[i]
                    row = df_sample.loc[idx]

                    q1, q3 = np.percentile(col_data, [25, 75])
                    iqr = q3 - q1
                    deviation = min(abs(col_data[i] - q1), abs(col_data[i] - q3))

                    report = (f"üîç –ú–µ—Ç–æ–¥: IQR (–±—ã—Å—Ç—Ä—ã–π)\n"
                              f"üìä –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {deviation / iqr:.3f} IQR\n"
                              f"üìç –°—Ç—Ä–æ–∫–∞: {idx}\n"
                              f"üö® –ê–Ω–æ–º–∞–ª—å–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞: {col} = {col_data[i]:.2f}\n")

                    results.append((idx, report))

        return results

    def _svm_analysis(self, df_sample: pd.DataFrame) -> List[Tuple[int, str]]:
        """–ê–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–º One-Class SVM"""
        results = []
        numeric_cols = df_sample.select_dtypes(include=[np.number]).columns.tolist()

        contamination = self.detector._get_optimal_contamination(len(df_sample))

        model = OneClassSVM(
            nu=contamination,
            kernel="rbf",
            gamma="scale"
        )

        scaler = RobustScaler()
        X_scaled = scaler.fit_transform(df_sample[numeric_cols])

        preds = model.fit_predict(X_scaled)
        scores = model.decision_function(X_scaled)

        anomaly_indices = df_sample[preds == -1].index

        for idx in anomaly_indices:
            score_idx = df_sample.index.get_loc(idx)
            row = df_sample.loc[idx]
            report = self.detector._generate_fast_anomaly_report(
                row, df_sample, method="One-Class SVM",
                score=scores[score_idx]
            )
            results.append((idx, report))

        return results

    def _elliptic_envelope_analysis(self, df_sample: pd.DataFrame) -> List[Tuple[int, str]]:
        """–ê–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–º Elliptic Envelope"""
        results = []
        numeric_cols = df_sample.select_dtypes(include=[np.number]).columns.tolist()

        contamination = self.detector._get_optimal_contamination(len(df_sample))

        model = EllipticEnvelope(
            contamination=contamination,
            random_state=42
        )

        scaler = RobustScaler()
        X_scaled = scaler.fit_transform(df_sample[numeric_cols])

        preds = model.fit_predict(X_scaled)
        scores = model.decision_function(X_scaled)

        anomaly_indices = df_sample[preds == -1].index

        for idx in anomaly_indices:
            score_idx = df_sample.index.get_loc(idx)
            row = df_sample.loc[idx]
            report = self.detector._generate_fast_anomaly_report(
                row, df_sample, method="Elliptic Envelope",
                score=scores[score_idx]
            )
            results.append((idx, report))

        return results

    def _auto_optimized_analysis(self, df_sample: pd.DataFrame) -> List[Tuple[int, str]]:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞"""
        sample_size = len(df_sample)

        if sample_size > 500000:
            # –î–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –±—ã—Å—Ç—Ä—ã–µ –º–µ—Ç–æ–¥—ã
            return self._fast_zscore_analysis(df_sample)
        elif sample_size > 100000:
            # –î–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º Isolation Forest
            return self.detector.isolation_forest_analysis(df_sample)
        elif sample_size > 10000:
            # –î–ª—è —Å—Ä–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            return self.detector.combined_analysis(df_sample)
        else:
            # –î–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            return self.detector.combined_analysis(df_sample)

    def _generate_optimized_stats_report(self, df_sample: pd.DataFrame):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç"""
        report = "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç (–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)\n\n"
        numeric_cols = df_sample.select_dtypes(include=[np.number]).columns.tolist()

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        report += f"–ò—Å—Ö–æ–¥–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {len(self.original_df) if self.original_df is not None else len(self.df):,}\n"
        report += f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {len(df_sample):,}\n"
        report += f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–Ω–æ–º–∞–ª–∏–π: {len(self.anomalies):,}\n"

        if len(df_sample) > 0:
            report += f"–ü—Ä–æ—Ü–µ–Ω—Ç –∞–Ω–æ–º–∞–ª–∏–π: {len(self.anomalies) / len(df_sample) * 100:.2f}%\n\n"

        # –ë—ã—Å—Ç—Ä–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º (—Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–≤—ã—Ö 10 –∫–æ–ª–æ–Ω–æ–∫)
        for col in numeric_cols[:10]:
            col_data = df_sample[col]
            report += f"üìå {col}:\n"
            report += f"‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ: {col_data.mean():.2f}\n"
            report += f"‚Ä¢ –ú–µ–¥–∏–∞–Ω–∞: {col_data.median():.2f}\n"
            report += f"‚Ä¢ –°—Ç–¥. –æ—Ç–∫–ª.: {col_data.std():.2f}\n"
            report += f"‚Ä¢ –î–∏–∞–ø–∞–∑–æ–Ω: [{col_data.min():.2f}, {col_data.max():.2f}]\n\n"

        if len(numeric_cols) > 10:
            report += f"... –∏ –µ—â–µ {len(numeric_cols) - 10} –∫–æ–ª–æ–Ω–æ–∫\n\n"

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if hasattr(self, 'start_time'):
            elapsed = time.time() - self.start_time
            report += f"‚ö° –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:\n"
            report += f"‚Ä¢ –í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {elapsed:.1f} —Å–µ–∫—É–Ω–¥\n"
            report += f"‚Ä¢ –°–∫–æ—Ä–æ—Å—Ç—å: {len(df_sample) / elapsed:.0f} —Å—Ç—Ä–æ–∫/—Å–µ–∫\n"
            report += f"‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {df_sample.memory_usage(deep=True).sum() / (1024 ** 2):.1f} MB\n"

        self.stats_text.delete(1.0, "end")
        self.stats_text.insert("end", report)

    def _display_optimized_results(self):
        """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        self.tree.delete(*self.tree.get_children())
        self.details_text.delete(1.0, "end")

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–ª–æ–Ω–æ–∫ —Ç–∞–±–ª–∏—Ü—ã
        self.tree["columns"] = ("row_id", "anomaly_type", "score", "cluster")
        self.tree.heading("row_id", text="–°—Ç—Ä–æ–∫–∞")
        self.tree.heading("anomaly_type", text="–¢–∏–ø")
        self.tree.heading("score", text="–°–∏–ª–∞")
        self.tree.heading("cluster", text="–ö–ª–∞—Å—Ç–µ—Ä")

        # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã (–ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 2000 –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
        display_limit = min(2000, len(self.anomalies))

        for i, (idx, desc) in enumerate(self.anomalies[:display_limit]):
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∞–Ω–æ–º–∞–ª–∏–∏
            if "–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π" in desc:
                anomaly_type = "–ö–æ–º–±–∏"
            elif "Isolation Forest" in desc:
                anomaly_type = "IsoFor"
            elif "Z-Score" in desc:
                anomaly_type = "Z-Score"
            elif "IQR" in desc:
                anomaly_type = "IQR"
            elif "Local Outlier Factor" in desc:
                anomaly_type = "LOF"
            elif "One-Class SVM" in desc:
                anomaly_type = "SVM"
            elif "Elliptic Envelope" in desc:
                anomaly_type = "Ellipse"
            else:
                anomaly_type = "–î—Ä—É–≥–æ–µ"

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è
            score = "N/A"
            lines = desc.split('\n')
            for line in lines:
                if '–ê–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç—å:' in line or '–ì–æ–ª–æ—Å–æ–≤:' in line or 'Z-Score:' in line:
                    try:
                        score = line.split(':')[1].strip()
                        if score.replace('.', '').replace('-', '').isdigit():
                            score = f"{float(score):.2f}"
                    except:
                        pass
                    break

            # –ü–æ–ª—É—á–∞–µ–º –∫–ª–∞—Å—Ç–µ—Ä
            cluster = self.cluster_map.get(idx, "-")
            if cluster == -1:
                cluster = "–ï–¥–∏–Ω."
            else:
                cluster = str(cluster)

            self.tree.insert(
                "", "end",
                text=str(i + 1),
                values=(idx, anomaly_type, score, cluster)
            )

        if len(self.anomalies) > display_limit:
            self.tree.insert(
                "", "end",
                text="...",
                values=(f"+ –µ—â–µ {len(self.anomalies) - display_limit}", "–∞–Ω–æ–º–∞–ª–∏–π", "", "")
            )

    def _show_anomaly_details(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–µ—Ç–∞–ª–∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∞–Ω–æ–º–∞–ª–∏–∏"""
        selected = self.tree.focus()
        if not selected:
            return

        item = self.tree.item(selected)
        if not item['values'] or item['text'] == "...":
            return

        row_id = item['values'][0]

        desc = next((desc for idx, desc in self.anomalies if idx == row_id), "")
        self.details_text.delete(1.0, "end")
        self.details_text.insert("end", desc)

    def _export_results(self):
        """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞"""
        if not self.anomalies:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return

        file_path = filedialog.asksaveasfilename(
            defaultextension=".xlsx",
            filetypes=[("Excel", "*.xlsx"), ("CSV", "*.csv"), ("JSON", "*.json")]
        )

        if not file_path:
            return

        try:
            self.status_var.set("–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
            self.progress_var.set(0)

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ (–æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
            export_data = []
            max_export = min(10000, len(self.anomalies))

            for i, (idx, desc) in enumerate(self.anomalies[:max_export]):
                if i % 1000 == 0:
                    self.progress_var.set(int(50 * i / max_export))
                    self.master.update()

                row_data = {
                    "row_id": idx,
                    "description": desc,
                    "cluster": self.cluster_map.get(idx, None)
                }

                # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
                if idx in self.df.index:
                    row_data.update(self.df.loc[idx].to_dict())

                export_data.append(row_data)

            export_df = pd.DataFrame(export_data)
            self.progress_var.set(75)

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            if file_path.endswith('.xlsx'):
                export_df.to_excel(file_path, index=False)
            elif file_path.endswith('.csv'):
                export_df.to_csv(file_path, index=False)
            elif file_path.endswith('.json'):
                export_df.to_json(file_path, orient='records', indent=2, force_ascii=False)

            self.progress_var.set(100)

            export_info = f"–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(export_data)} –∞–Ω–æ–º–∞–ª–∏–π"
            if len(self.anomalies) > max_export:
                export_info += f" –∏–∑ {len(self.anomalies)} (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)"

            messagebox.showinfo("–£—Å–ø–µ—Ö", f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —É—Å–ø–µ—à–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã\n\n{export_info}")

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {str(e)}", exc_info=True)
            messagebox.showerror("–û—à–∏–±–∫–∞", f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞:\n{str(e)}")
        finally:
            self.progress_var.set(0)

    def _generate_report(self, report_type: str = "html"):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
        if not self.anomalies:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç—á—ë—Ç–∞")
            return

        file_path = filedialog.asksaveasfilename(
            defaultextension=f".{report_type}",
            filetypes=[(report_type.upper(), f"*.{report_type}")]
        )

        if not file_path:
            return

        try:
            self.status_var.set("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞...")
            self.progress_var.set(0)

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç—á–µ—Ç–∞, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
            df_for_report = self.original_df if self.original_df is not None else self.df

            if report_type == "html":
                ReportGenerator.generate_html_report(df_for_report, self.anomalies, file_path)
            elif report_type == "pdf":
                ReportGenerator.generate_pdf_report(df_for_report, self.anomalies, file_path)

            self.progress_var.set(100)
            messagebox.showinfo("–£—Å–ø–µ—Ö", "–û—Ç—á—ë—Ç —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")

            # –û—Ç–∫—Ä—ã–≤–∞–µ–º –æ—Ç—á–µ—Ç –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
            if report_type == "html":
                webbrowser.open(file_path)

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á—ë—Ç–∞: {str(e)}", exc_info=True)
            messagebox.showerror("–û—à–∏–±–∫–∞", f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á—ë—Ç–∞:\n{str(e)}")
        finally:
            self.progress_var.set(0)

    def _show_scatter_plot(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–æ—á–µ—á–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ —Å –∞–Ω–æ–º–∞–ª–∏—è–º–∏"""
        if not hasattr(self, 'anomalies') or not self.anomalies:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö")
            return

        numeric_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
        if len(numeric_cols) < 2:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
            return

        # –û–∫–Ω–æ –≤—ã–±–æ—Ä–∞ —Å—Ç–æ–ª–±—Ü–æ–≤
        selector = tk.Toplevel(self.master)
        selector.title("–í—ã–±–æ—Ä —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞")
        selector.geometry("400x300")

        ttk.Label(selector, text="–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏").pack(pady=10)

        x_var = tk.StringVar(value=numeric_cols[0])
        y_var = tk.StringVar(value=numeric_cols[1] if len(numeric_cols) > 1 else numeric_cols[0])
        color_var = tk.StringVar(value="None")

        # –í—ã–±–æ—Ä –æ—Å–∏ X
        ttk.Label(selector, text="–û—Å—å X:").pack()
        ttk.Combobox(selector, textvariable=x_var, values=numeric_cols).pack()

        # –í—ã–±–æ—Ä –æ—Å–∏ Y
        ttk.Label(selector, text="–û—Å—å Y:").pack()
        ttk.Combobox(selector, textvariable=y_var, values=numeric_cols).pack()

        # –í—ã–±–æ—Ä —Ü–≤–µ—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        ttk.Label(selector, text="–¶–≤–µ—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):").pack(pady=(10, 0))
        color_options = ["None"] + numeric_cols
        ttk.Combobox(selector, textvariable=color_var, values=color_options).pack()

        def show_plot():
            x_col = x_var.get()
            y_col = y_var.get()
            color_col = color_var.get() if color_var.get() != "None" else None

            # –î–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–¥–≤—ã–±–æ—Ä–∫—É –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            df_plot = self.df
            if len(self.df) > 50000:
                df_plot = self.df.sample(n=50000, random_state=42)

            if color_col:
                fig = px.scatter(
                    df_plot,
                    x=x_col,
                    y=y_col,
                    color=color_col,
                    color_continuous_scale=px.colors.sequential.Viridis,
                    hover_data=df_plot.columns.tolist()[:10],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º hover –¥–∞–Ω–Ω—ã–µ
                    title=f"{y_col} vs {x_col} (—Ü–≤–µ—Ç: {color_col})"
                )

                # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–æ–º–∞–ª–∏–∏ (—Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 1000 –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
                anomalies_subset = [a for a in self.anomalies[:1000] if a[0] in df_plot.index]
                if anomalies_subset:
                    anomalies_df = df_plot.loc[[a[0] for a in anomalies_subset]]
                    fig.add_trace(
                        go.Scatter(
                            x=anomalies_df[x_col],
                            y=anomalies_df[y_col],
                            mode="markers",
                            marker=dict(color='red', size=8, line=dict(width=1, color='DarkSlateGrey')),
                            name="–ê–Ω–æ–º–∞–ª–∏–∏",
                            hoverinfo='text',
                            text=[f"–°—Ç—Ä–æ–∫–∞: {idx}" for idx in anomalies_df.index]
                        )
                    )
            else:
                fig = EnhancedVisuals.scatter_plot(
                    df_plot,
                    self.anomalies[:1000],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–Ω–æ–º–∞–ª–∏–π
                    x_col,
                    y_col,
                    title=f"{y_col} vs {x_col}"
                )

            self._show_plot(fig)
            selector.destroy()

        ttk.Button(selector, text="–ü–æ–∫–∞–∑–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫", command=show_plot).pack(pady=10)

    def _show_parallel_coords(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç"""
        if not hasattr(self, 'anomalies') or not self.anomalies:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö")
            return

        numeric_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
        if len(numeric_cols) < 2:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
            return

        # –î–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–¥–≤—ã–±–æ—Ä–∫—É
        df_plot = self.df
        if len(self.df) > 10000:
            df_plot = self.df.sample(n=10000, random_state=42)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        cols_to_plot = numeric_cols[:8]

        fig = EnhancedVisuals.parallel_coordinates(df_plot, self.anomalies[:1000], cols_to_plot)
        self._show_plot(fig)

    def _show_time_series(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ —Å –∞–Ω–æ–º–∞–ª–∏—è–º–∏"""
        if not hasattr(self, 'anomalies') or not self.anomalies:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö")
            return

        # –ù–∞—Ö–æ–¥–∏–º —Å—Ç–æ–ª–±—Ü—ã —Å –¥–∞—Ç–æ–π/–≤—Ä–µ–º–µ–Ω–µ–º
        time_cols = [col for col in self.df.columns
                     if self.df[col].dtype in ['datetime64[ns]', 'object'] and
                     any(keyword in col.lower() for keyword in ['date', 'time', 'year', 'month', 'day'])]

        if not time_cols:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–ù–µ –Ω–∞–π–¥–µ–Ω —Å—Ç–æ–ª–±–µ—Ü —Å –¥–∞—Ç–æ–π/–≤—Ä–µ–º–µ–Ω–µ–º")
            return

        numeric_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
        if not numeric_cols:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–ù–µ –Ω–∞–π–¥–µ–Ω—ã —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
            return

        # –û–∫–Ω–æ –≤—ã–±–æ—Ä–∞ —Å—Ç–æ–ª–±—Ü–æ–≤
        selector = tk.Toplevel(self.master)
        selector.title("–í—ã–±–æ—Ä —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞")
        selector.geometry("400x200")

        ttk.Label(selector, text="–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏").pack(pady=10)

        time_var = tk.StringVar(value=time_cols[0])
        value_var = tk.StringVar(value=numeric_cols[0])

        ttk.Label(selector, text="–í—Ä–µ–º–µ–Ω–Ω–∞—è –æ—Å—å:").pack()
        ttk.Combobox(selector, textvariable=time_var, values=time_cols).pack()

        ttk.Label(selector, text="–ó–Ω–∞—á–µ–Ω–∏–µ:").pack()
        ttk.Combobox(selector, textvariable=value_var, values=numeric_cols).pack()

        def show_plot():
            time_col = time_var.get()
            value_col = value_var.get()

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ datetime, –µ—Å–ª–∏ –µ—â–µ –Ω–µ
            if not pd.api.types.is_datetime64_any_dtype(self.df[time_col]):
                try:
                    self.df[time_col] = pd.to_datetime(self.df[time_col])
                except:
                    messagebox.showerror("–û—à–∏–±–∫–∞", f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å '{time_col}' –≤ –¥–∞—Ç—É/–≤—Ä–µ–º—è")
                    return

            # –î–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–¥–≤—ã–±–æ—Ä–∫—É
            df_plot = self.df
            if len(self.df) > 20000:
                df_plot = self.df.sample(n=20000, random_state=42).sort_values(time_col)

            fig = EnhancedVisuals.time_series_plot(
                df_plot,
                [a for a in self.anomalies[:1000] if a[0] in df_plot.index],
                time_col,
                value_col,
                title=f"–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥: {value_col}"
            )
            self._show_plot(fig)
            selector.destroy()

        ttk.Button(selector, text="–ü–æ–∫–∞–∑–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫", command=show_plot).pack(pady=10)

    def _show_histogram(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å –∞–Ω–æ–º–∞–ª–∏—è–º–∏"""
        if not hasattr(self, 'anomalies') or not self.anomalies:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö")
            return

        numeric_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
        if not numeric_cols:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–ù–µ –Ω–∞–π–¥–µ–Ω—ã —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
            return

        # –û–∫–Ω–æ –≤—ã–±–æ—Ä–∞ —Å—Ç–æ–ª–±—Ü–∞
        selector = tk.Toplevel(self.master)
        selector.title("–í—ã–±–æ—Ä —Å—Ç–æ–ª–±—Ü–∞ –¥–ª—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã")
        selector.geometry("300x150")

        ttk.Label(selector, text="–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü:").pack(pady=10)

        col_var = tk.StringVar(value=numeric_cols[0])
        ttk.Combobox(selector, textvariable=col_var, values=numeric_cols).pack()

        def show_plot():
            fig = EnhancedVisuals.show_histogram(
                self.df,
                col_var.get(),
                self.anomalies[:1000],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                title=f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {col_var.get()}"
            )
            self._show_plot(fig)
            selector.destroy()

        ttk.Button(selector, text="–ü–æ–∫–∞–∑–∞—Ç—å", command=show_plot).pack(pady=10)

    def _show_boxplot(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –±–æ–∫—Å–ø–ª–æ—Ç —Å –∞–Ω–æ–º–∞–ª–∏—è–º–∏"""
        if not hasattr(self, 'anomalies') or not self.anomalies:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö")
            return

        numeric_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
        if not numeric_cols:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–ù–µ –Ω–∞–π–¥–µ–Ω—ã —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
            return

        # –û–∫–Ω–æ –≤—ã–±–æ—Ä–∞ —Å—Ç–æ–ª–±—Ü–∞
        selector = tk.Toplevel(self.master)
        selector.title("–í—ã–±–æ—Ä —Å—Ç–æ–ª–±—Ü–∞ –¥–ª—è –±–æ–∫—Å–ø–ª–æ—Ç–∞")
        selector.geometry("300x150")

        ttk.Label(selector, text="–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü:").pack(pady=10)

        col_var = tk.StringVar(value=numeric_cols[0])
        ttk.Combobox(selector, textvariable=col_var, values=numeric_cols).pack()

        def show_plot():
            fig = EnhancedVisuals.show_boxplot(
                self.df,
                col_var.get(),
                self.anomalies[:1000],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                title=f"–ë–æ–∫—Å–ø–ª–æ—Ç {col_var.get()}"
            )
            self._show_plot(fig)
            selector.destroy()

        ttk.Button(selector, text="–ü–æ–∫–∞–∑–∞—Ç—å", command=show_plot).pack(pady=10)

    def _show_clusters(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é –∞–Ω–æ–º–∞–ª–∏–π"""
        if not hasattr(self, 'cluster_map') or not self.cluster_map:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–µ–π")
            return

        numeric_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
        if len(numeric_cols) < 2:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
            return

        # –û–∫–Ω–æ –≤—ã–±–æ—Ä–∞ —Å—Ç–æ–ª–±—Ü–æ–≤
        selector = tk.Toplevel(self.master)
        selector.title("–í—ã–±–æ—Ä —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")
        selector.geometry("400x200")

        ttk.Label(selector, text="–í—ã–±–µ—Ä–∏—Ç–µ –æ—Å–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤").pack(pady=10)

        x_var = tk.StringVar(value=numeric_cols[0])
        y_var = tk.StringVar(value=numeric_cols[1] if len(numeric_cols) > 1 else numeric_cols[0])

        ttk.Label(selector, text="–û—Å—å X:").pack()
        ttk.Combobox(selector, textvariable=x_var, values=numeric_cols).pack()

        ttk.Label(selector, text="–û—Å—å Y:").pack()
        ttk.Combobox(selector, textvariable=y_var, values=numeric_cols).pack()

        def show_plot():
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–Ω–æ–º–∞–ª–∏–π –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            anomalies_to_show = [a[0] for a in self.anomalies[:2000]]

            fig = OptimizedAnomalyClustering.visualize_clusters(
                self.df,
                anomalies_to_show,
                self.cluster_map,
                x_var.get(),
                y_var.get(),
                title="–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π"
            )
            self._show_plot(fig)
            selector.destroy()

        ttk.Button(selector, text="–ü–æ–∫–∞–∑–∞—Ç—å", command=show_plot).pack(pady=10)


if __name__ == "__main__":
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
    try:
        import psutil
        import numba
    except ImportError as e:
        print(f"–í–Ω–∏–º–∞–Ω–∏–µ: –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install psutil numba")
        print(f"–û—à–∏–±–∫–∞: {e}")

    root = tk.Tk()
    app = AdvancedAnomalyDetector(root)
    root.mainloop()
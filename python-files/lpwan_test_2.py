# -*- coding: utf-8 -*-
"""lpwan test 2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XRJx7baEXi-FOsmdOi9jM0MzeNXND6gk
"""

import requests
import pandas as pd
import matplotlib.pyplot as plt

# NASA POWER API (Matale: 7.4675Â° N, 80.6234Â° E)
latitude = 7.4675
longitude = 80.6234
start_date = "2018-01-01"
end_date = "2023-12-31"

# Make request
url = f"https://power.larc.nasa.gov/api/temporal/daily/point?parameters=T2M&community=RE&longitude={longitude}&latitude={latitude}&start={start_date.replace('-','')}&end={end_date.replace('-','')}&format=JSON"

response = requests.get(url)
print(f"Status Code: {response.status_code}")

# DEBUG: Show response if error
try:
    data = response.json()
    daily_data = data['properties']['parameter']['T2M']
except KeyError as e:
    print("âš ï¸ ERROR: Couldn't find expected key in response. Full response content:")
    print(response.text)
    raise e

# STEP 1: Handle Missing Values (if any)
print("Missing values before cleaning:")
print(df.isnull().sum())

# Drop or fill missing values
df_clean = df.dropna()  # You can also use .fillna(method='ffill') if preferred

# STEP 2: Check for Outliers (optional visualization)
plt.figure(figsize=(8,4))
plt.boxplot(df_clean['Temperature'])
plt.title("Boxplot to Check for Outliers")
plt.show()

# Optional: Remove outliers (only if extreme)
q1 = df_clean['Temperature'].quantile(0.25)
q3 = df_clean['Temperature'].quantile(0.75)
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr

df_clean = df_clean[(df_clean['Temperature'] >= lower_bound) & (df_clean['Temperature'] <= upper_bound)]

# STEP 3: Set 'Date' as index
df_clean.set_index('Date', inplace=True)

# STEP 4: Optional Resampling (if daily is too dense)
# df_clean = df_clean.resample('M').mean()  # Uncomment if you want monthly averages

# STEP 5: Visualize Cleaned Data
plt.figure(figsize=(14, 5))
plt.plot(df_clean.index, df_clean['Temperature'], color='teal')
plt.title("Cleaned Daily Temperature Data â€“ Matale")
plt.xlabel("Date")
plt.ylabel("Temperature (Â°C)")
plt.grid(True)
plt.show()

# Final check
print("Cleaned data shape:", df_clean.shape)
df_clean.head()

import pandas as pd

# Extract the temperature data
temperature_data = data['properties']['parameter']['T2M']  # Daily average temperature

# Convert to a DataFrame
df = pd.DataFrame(list(temperature_data.items()), columns=['Date', 'Temperature'])

# Convert the 'Date' column to datetime format
df['Date'] = pd.to_datetime(df['Date'])

# Sort by date (just in case)
df = df.sort_values('Date')

# Reset index
df.reset_index(drop=True, inplace=True)

# Check for missing values
missing = df.isnull().sum()
print("Missing values:\n", missing)

# Display cleaned data
df.head()

import requests
import pandas as pd

# Matale coordinates
lat, lon = 7.4675, 80.6233

# NASA POWER API URL
url = f"https://power.larc.nasa.gov/api/temporal/daily/point?parameters=T2M&community=AG&latitude={lat}&longitude={lon}&start=20180101&end=20211231&format=JSON"

# Request data
response = requests.get(url)
data = response.json()

# Extract temperature values
temps = data['properties']['parameter']['T2M']

# Create DataFrame
df = pd.DataFrame(list(temps.items()), columns=['date', 'temperature'])
df['date'] = pd.to_datetime(df['date'])
df = df.sort_values('date')
df.reset_index(drop=True, inplace=True)

# Check
df.head()

from sklearn.preprocessing import MinMaxScaler
import numpy as np

# Scale the temperatures
scaler = MinMaxScaler()
temps_scaled = scaler.fit_transform(df[['temperature']].values)

# Create sequences
def create_sequences(data, seq_length=30):
    x = []
    y = []
    for i in range(seq_length, len(data)):
        x.append(data[i-seq_length:i])
        y.append(data[i])
    return np.array(x), np.array(y)

X, y = create_sequences(temps_scaled)

# Train-test split
split = int(len(X) * 0.8)
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

X_train.shape, y_train.shape

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Define the model
model = Sequential()
model.add(LSTM(units=64, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dense(units=1))  # One output value (temperature)

# Compile the model
model.compile(optimizer='adam', loss='mse')

# Train the model
history = model.fit(X_train, y_train, epochs=30, batch_size=16, validation_split=0.2)

# Plot training history
import matplotlib.pyplot as plt

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Model Training Performance')
plt.grid(True)
plt.show()

from sklearn.preprocessing import MinMaxScaler

# Re-scale the temperature values
scaler = MinMaxScaler()
temps_scaled = scaler.fit_transform(df[['temperature']])

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Make predictions
y_pred = model.predict(X_test)

# Inverse transform to get actual temperature values
y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))
y_pred_inv = scaler.inverse_transform(y_pred)

# Calculate error metrics
mae = mean_absolute_error(y_test_inv, y_pred_inv)
rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))
r2 = r2_score(y_test_inv, y_pred_inv)

# Display metrics
print(f"Mean Absolute Error (MAE): {mae:.2f}Â°C")
print(f"Root Mean Square Error (RMSE): {rmse:.2f}Â°C")
print(f"RÂ² Score: {r2:.4f}")

# Make predictions
y_pred = model.predict(X_test)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Inverse transform to get actual temperature values
y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))
y_pred_inv = scaler.inverse_transform(y_pred)

# Calculate error metrics
mae = mean_absolute_error(y_test_inv, y_pred_inv)
rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))
r2 = r2_score(y_test_inv, y_pred_inv)

# Display metrics
print(f"Mean Absolute Error (MAE): {mae:.2f}Â°C")
print(f"Root Mean Square Error (RMSE): {rmse:.2f}Â°C")
print(f"RÂ² Score: {r2:.4f}")

import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Inverse transform to get actual temperature values
y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))
y_pred_inv = scaler.inverse_transform(y_pred)

plt.figure(figsize=(10, 5))
plt.plot(y_test_inv, label='Actual Temperature', color='blue')
plt.plot(y_pred_inv, label='Predicted Temperature', color='orange')
plt.title("Actual vs Predicted Temperature (Matale)")
plt.xlabel("Days")
plt.ylabel("Temperature (Â°C)")
plt.legend()
plt.grid(True)
plt.show()

# Number of days to predict
future_days = 7
sequence_length = 30

# Start from the last known sequence
last_sequence = temps_scaled[-sequence_length:]
current_sequence = np.expand_dims(last_sequence, axis=0)

# Store predictions
future_predictions = []

for _ in range(future_days):
    # Predict next temperature
    predicted_temp = model.predict(current_sequence)[0, 0]

    # Append prediction
    future_predictions.append(predicted_temp)

    # Update the sequence: remove oldest, append newest
    new_sequence = np.append(current_sequence[0, 1:], [[predicted_temp]], axis=0)
    current_sequence = np.expand_dims(new_sequence, axis=0)

# Inverse scale to get actual temperature values
future_predictions_actual = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))

# Display results
for i, temp in enumerate(future_predictions_actual, 1):
    print(f"Day {i}: Predicted Temperature = {temp[0]:.2f} Â°C")

plt.figure(figsize=(8, 4))
plt.plot(range(1, future_days + 1), future_predictions_actual, marker='o', color='green')
plt.title("7-Day Future Temperature Prediction (Matale)")
plt.xlabel("Day")
plt.ylabel("Predicted Temperature (Â°C)")
plt.grid(True)
plt.show()

# Number of days to predict
future_days = 7
sequence_length = 30

# Get the last sequence from the scaled data
last_sequence = temps_scaled[-sequence_length:]
current_sequence = np.expand_dims(last_sequence, axis=0)

# Store predictions
future_predictions = []

for _ in range(future_days):
    predicted_temp = model.predict(current_sequence)[0, 0]
    future_predictions.append(predicted_temp)

    # Shift the sequence and add the new prediction
    last_sequence = np.append(last_sequence[1:], [[predicted_temp]], axis=0)
    current_sequence = np.expand_dims(last_sequence, axis=0)

# Inverse transform to original temperature scale
future_predictions_actual = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))

# Print results
print("ðŸ“… 7-Day Temperature Forecast (Matale):")
for i, temp in enumerate(future_predictions_actual, 1):
    print(f"Day {i}: Predicted Temperature = {temp[0]:.2f} Â°C")

plt.figure(figsize=(8, 4))
plt.plot(range(1, future_days + 1), future_predictions_actual, marker='o', color='green')
plt.title("ðŸŒ¡ï¸ 7-Day Future Temperature Prediction - Matale")
plt.xlabel("Day")
plt.ylabel("Predicted Temperature (Â°C)")
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd
from datetime import datetime, timedelta

# Generate dates for the next 7 days
start_date = datetime.today()
future_dates = [start_date + timedelta(days=i) for i in range(1, 8)]

# Prepare DataFrame
forecast_df = pd.DataFrame({
    'Date': [date.strftime('%Y-%m-%d') for date in future_dates],
    'Predicted_Temperature_C': future_predictions_actual.flatten()
})

# Save to CSV
forecast_df.to_csv('matale_7_day_forecast.csv', index=False)

print("âœ… Forecast saved as 'matale_7_day_forecast.csv' successfully!")

# Optional: Display table in notebook
forecast_df

import requests

# Replace with your actual Write API key
THINGSPEAK_WRITE_API = "JGT47S02AW4KDB0W"

# Replace with your 7-day predicted temperatures from model
predictions = [30.2, 29.8, 30.5, 31.0, 30.1, 29.7, 30.3]  # Example only

# Build the query parameters
url = f"https://api.thingspeak.com/update?api_key={THINGSPEAK_WRITE_API}"
for i, value in enumerate(predictions, start=1):
    url += f"&field{i}={value}"

# Optional: Add confidence to Field 8
confidence = 95.3
url += f"&field8={confidence}"

# Send request
response = requests.get(url)

if response.status_code == 200:
    print("âœ… Prediction data sent to ThingSpeak!")
else:
    print("âŒ Failed to send data:", response.status_code, response.text)

import requests
import pandas as pd
import time

# Your ThingSpeak Write API Key for Historical Data Channel
thingspeak_api_key = "CIYDR4N8SJJZKEE7"  # <-- Replace this

# 1. NASA POWER API - Get temperature for Matale (Lat 7.4675, Lon 80.6234)
start_date = "2024-06-01"
end_date = "2024-06-10"

nasa_url = f"https://power.larc.nasa.gov/api/temporal/daily/point?parameters=T2M&community=RE&start={start_date.replace('-','')}&end={end_date.replace('-','')}&latitude=7.4675&longitude=80.6234&format=JSON"

response = requests.get(nasa_url)
data = response.json()

# DEBUG: Print the response data to understand its structure
print("API Response Data:")
print(data)


# 2. Extract daily temperature values
temps = list(data['properties']['parameter']['T2M'].values())
dates = list(data['properties']['parameter']['T2M'].keys())

print("Uploading temperatures to ThingSpeak...")

# 3. Upload to ThingSpeak
for temp, date in zip(temps, dates):
    upload_url = f"https://api.thingspeak.com/update?api_key={thingspeak_api_key}&field1={temp}"
    r = requests.get(upload_url)
    print(f"Date: {date}, Temp: {temp}Â°C, Response: {r.text}")
    time.sleep(15)  # ThingSpeak Free Tier Limit